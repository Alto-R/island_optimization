{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff73fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Set up plotting parameters\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "def load_and_process_data():\n",
    "    \"\"\"Load real data or generate mock data for demonstration\"\"\"\n",
    "    try:\n",
    "        # Try to load real data\n",
    "        demand_data = pd.read_csv(\"../demand_get/data/get1/demand_60.15269_-45.27849.csv\")\n",
    "        system_output = pd.read_csv('../result/output_0/60.15269_-45.27849_results.csv', \n",
    "                                   usecols=['WT', 'PV', 'WEC'])\n",
    "        print(f\"âœ“ Loaded real data:\")\n",
    "        print(f\"  - Demand data: {len(demand_data)} hours (1-hour resolution)\")\n",
    "        print(f\"  - System output: {len(system_output)} periods (3-hour resolution)\")\n",
    "        \n",
    "        # Get heating demand (try different possible column names)\n",
    "        demand_columns = ['heating_demand', 'Heating_Demand', 'demand', 'Demand']\n",
    "        demand_col = None\n",
    "        for col in demand_columns:\n",
    "            if col in demand_data.columns:\n",
    "                demand_col = col\n",
    "                break\n",
    "        \n",
    "        if demand_col is None and len(demand_data.columns) > 0:\n",
    "            demand_col = demand_data.columns[0]\n",
    "            print(f\"Using first available column as demand: {demand_col}\")\n",
    "        \n",
    "        heating_demand = demand_data[demand_col].values\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"ğŸ“„ Real data files not found. Generating mock data for demonstration...\")\n",
    "        # Generate one full year of data\n",
    "        # Demand: hourly resolution (8760 hours)\n",
    "        hours_per_year = 8760\n",
    "        periods_per_year = hours_per_year // 3  # 2920 3-hour periods\n",
    "        \n",
    "        # Generate hourly demand data\n",
    "        time_index_hourly = np.arange(hours_per_year)\n",
    "        seasonal_demand = 400 + 300 * np.cos(2 * np.pi * (time_index_hourly - 2160) / hours_per_year)\n",
    "        daily_variation = 100 * np.sin(2 * np.pi * time_index_hourly / 24)\n",
    "        heating_demand = np.maximum(100, seasonal_demand + daily_variation + 50 * np.random.randn(hours_per_year))\n",
    "        \n",
    "        # Generate 3-hourly system output data\n",
    "        time_index_3h = np.arange(periods_per_year)\n",
    "        time_hours_3h = time_index_3h * 3  # Convert to equivalent hours\n",
    "        \n",
    "        # Wind power: higher in winter, variable\n",
    "        wind_seasonal = 200 + 150 * np.cos(2 * np.pi * (time_hours_3h - 1440) / hours_per_year)\n",
    "        wind_variation = 100 * np.random.randn(periods_per_year)\n",
    "        wt_output = np.maximum(0, wind_seasonal + wind_variation)\n",
    "        \n",
    "        # Solar PV: higher in summer, with 3-hour averages\n",
    "        solar_seasonal = 150 * np.maximum(0, np.sin(2 * np.pi * (time_hours_3h - 4380) / hours_per_year))\n",
    "        # Simulate day/night cycle for 3-hour periods\n",
    "        solar_daily = 200 * np.maximum(0, np.sin(2 * np.pi * time_hours_3h / 24))\n",
    "        pv_output = np.maximum(0, solar_seasonal + solar_daily + 30 * np.random.randn(periods_per_year))\n",
    "        \n",
    "        # WEC power: more consistent\n",
    "        wec_base = 120 + 50 * np.cos(2 * np.pi * time_hours_3h / hours_per_year)\n",
    "        wec_output = np.maximum(20, wec_base + 40 * np.random.randn(periods_per_year))\n",
    "        \n",
    "        system_output = pd.DataFrame({\n",
    "            'WT': wt_output,\n",
    "            'PV': pv_output, \n",
    "            'WEC': wec_output\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ“ Generated mock data:\")\n",
    "        print(f\"  - Demand data: {len(heating_demand)} hours (1-hour resolution)\")\n",
    "        print(f\"  - System output: {len(system_output)} periods (3-hour resolution)\")\n",
    "    \n",
    "    return heating_demand, system_output\n",
    "\n",
    "def resample_demand_to_3hour(hourly_demand):\n",
    "    \"\"\"Resample hourly demand data to 3-hour resolution by taking mean\"\"\"\n",
    "    n_hours = len(hourly_demand)\n",
    "    n_3hours = n_hours // 3\n",
    "    \n",
    "    # Reshape and take mean of every 3 hours\n",
    "    reshaped = hourly_demand[:n_3hours * 3].reshape(-1, 3)\n",
    "    demand_3h = np.mean(reshaped, axis=1)\n",
    "    \n",
    "    print(f\"ğŸ”„ Resampled demand from {n_hours} hours to {len(demand_3h)} 3-hour periods\")\n",
    "    return demand_3h\n",
    "\n",
    "def smooth_data(data, window_periods=7*8):\n",
    "    \"\"\"Apply Savitzky-Golay smoothing (window in 3-hour periods)\"\"\"\n",
    "    # For 3-hour data: 7 days = 7*8 = 56 periods\n",
    "    window_3h = max(3, window_periods)\n",
    "    if window_3h % 2 == 0:  # Ensure odd window size\n",
    "        window_3h += 1\n",
    "    \n",
    "    polyorder = min(2, window_3h - 1)\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        smoothed = data.copy()\n",
    "        for col in data.columns:\n",
    "            smoothed[col] = np.maximum(0, savgol_filter(data[col], window_3h, polyorder))\n",
    "        return smoothed\n",
    "    else:\n",
    "        return savgol_filter(data, window_3h, polyorder)\n",
    "\n",
    "def create_monthly_ticks(n_periods):\n",
    "    \"\"\"Create month-based x-axis ticks for 3-hour resolution data\"\"\"\n",
    "    # For 3-hour resolution: 8 periods per day, ~240 periods per month\n",
    "    periods_per_month = [\n",
    "        31*8, 28*8, 31*8, 30*8, 31*8, 30*8,  # Jan-Jun\n",
    "        31*8, 31*8, 30*8, 31*8, 30*8, 31*8   # Jul-Dec\n",
    "    ]\n",
    "    \n",
    "    month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    # Calculate cumulative positions for month boundaries\n",
    "    cumulative_periods = np.cumsum([0] + periods_per_month)\n",
    "    \n",
    "    # Only include months that fit within our data\n",
    "    valid_ticks = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    for i, (pos, label) in enumerate(zip(cumulative_periods, month_labels)):\n",
    "        if pos < n_periods:\n",
    "            valid_ticks.append(pos)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    return valid_ticks, valid_labels\n",
    "\n",
    "def plot_energy_profile(heating_demand, system_output):\n",
    "    \"\"\"Create the main energy supply and demand plot\"\"\"\n",
    "    \n",
    "    # Resample demand from hourly to 3-hour resolution\n",
    "    print(\"ğŸ”„ Processing data resolutions...\")\n",
    "    demand_3h = resample_demand_to_3hour(heating_demand)\n",
    "    \n",
    "    # Ensure both datasets have the same length\n",
    "    min_length = min(len(demand_3h), len(system_output))\n",
    "    demand_3h = demand_3h[:min_length]\n",
    "    output_3h = system_output.iloc[:min_length].copy()\n",
    "    \n",
    "    print(f\"âœ“ Final data length: {min_length} 3-hour periods\")\n",
    "    \n",
    "    # Apply smoothing to both demand and output\n",
    "    print(\"ğŸ“ˆ Applying smoothing...\")\n",
    "    smooth_demand = smooth_data(demand_3h)\n",
    "    smooth_output = smooth_data(output_3h)\n",
    "    \n",
    "    # Create stacked data for area plot\n",
    "    stacked_data = pd.DataFrame(index=smooth_output.index)\n",
    "    stacked_data['WEC'] = smooth_output['WEC']  # Bottom layer\n",
    "    stacked_data['WT'] = stacked_data['WEC'] + smooth_output['WT']  # WEC + WT  \n",
    "    stacked_data['PV'] = stacked_data['WT'] + smooth_output['PV']   # WEC + WT + PV\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=300)\n",
    "    \n",
    "    # Define colors\n",
    "    colors = {\n",
    "        'WEC': '#1f77b4',      # Blue for Wave Energy Converter\n",
    "        'WT': '#87ceeb',       # Light blue for Wind Turbine  \n",
    "        'PV': '#ffcc00',       # Gold for Solar PV\n",
    "        'Heating': '#d62728'   # Red for Heating Demand\n",
    "    }\n",
    "    \n",
    "    # Time axis (3-hour periods)\n",
    "    time_axis = np.arange(len(smooth_output))\n",
    "    \n",
    "    # Plot stacked areas\n",
    "    ax.fill_between(time_axis, 0, stacked_data['WEC'], \n",
    "                   color=colors['WEC'], alpha=0.8, label='Wave Energy Converter (WEC)')\n",
    "    ax.fill_between(time_axis, stacked_data['WEC'], stacked_data['WT'],\n",
    "                   color=colors['WT'], alpha=0.8, label='Wind Turbine (WT)')\n",
    "    ax.fill_between(time_axis, stacked_data['WT'], stacked_data['PV'],\n",
    "                   color=colors['PV'], alpha=0.8, label='Solar PV')\n",
    "    \n",
    "    # Add boundary lines for clarity\n",
    "    ax.plot(time_axis, stacked_data['WEC'], color='white', linewidth=0.5, alpha=0.7)\n",
    "    ax.plot(time_axis, stacked_data['WT'], color='white', linewidth=0.5, alpha=0.7)\n",
    "    ax.plot(time_axis, stacked_data['PV'], color='white', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Plot heating demand line\n",
    "    ax.plot(time_axis, smooth_demand, color=colors['Heating'], \n",
    "           linewidth=3, label='Heating Demand', zorder=5)\n",
    "    \n",
    "    # Set up x-axis with monthly labels\n",
    "    month_ticks, month_labels = create_monthly_ticks(len(time_axis))\n",
    "    ax.set_xticks(month_ticks)\n",
    "    ax.set_xticklabels(month_labels)\n",
    "    \n",
    "    # Labels and formatting\n",
    "    ax.set_xlabel('Month', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Power (kW)', fontsize=16, fontweight='bold')\n",
    "    # ax.set_title('Annual Renewable Energy Supply vs. Heating Demand Profile\\n(3-Hour Resolution)', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "    ax.yaxis.set_tick_params(labelsize=16)\n",
    "    # Set axis limits\n",
    "    y_max = max(stacked_data['PV'].max(), smooth_demand.max()) * 1.1\n",
    "    ax.set_ylim(0, y_max)\n",
    "    ax.set_xlim(0, len(time_axis) - 1)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', fontsize=16, frameon=True, fancybox=True, shadow=False)\n",
    "    \n",
    "    # Grid for better readability\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print some statistics\n",
    "    total_renewable = stacked_data['PV'].iloc[-1] if len(stacked_data) > 0 else 0\n",
    "    avg_demand = smooth_demand.mean() if len(smooth_demand) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Statistics (3-hour resolution):\")\n",
    "    print(f\"   Average renewable generation: {total_renewable:.1f} kW\")  \n",
    "    print(f\"   Average heating demand: {avg_demand:.1f} kW\")\n",
    "    print(f\"   Data periods: {len(time_axis)} (3-hour periods)\")\n",
    "    if avg_demand > 0:\n",
    "        print(f\"   Renewable coverage: {(total_renewable/avg_demand*100):.1f}%\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Main execution\n",
    "print(\"ğŸš€ Loading and processing energy data...\")\n",
    "heating_demand, system_output = load_and_process_data()\n",
    "\n",
    "print(\"ğŸ¨ Creating visualization...\")\n",
    "fig, ax = plot_energy_profile(heating_demand, system_output)\n",
    "\n",
    "print(\"âœ… Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd697ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from geopy.distance import great_circle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def load_island_lng_data():\n",
    "    \"\"\"Load island and LNG terminal data\"\"\"\n",
    "    print(\"ğŸï¸ Loading island data...\")\n",
    "    # Read island data\n",
    "    islands = pd.read_csv(\"../visualization/filtered_island_1898.csv\")\n",
    "    # Clean column names and extract coordinates\n",
    "    islands.columns = [col.strip() for col in islands.columns]\n",
    "    if 'Long' in islands.columns and 'Lat' in islands.columns:\n",
    "        islands['lon'] = islands['Long']\n",
    "        islands['lat'] = islands['Lat']\n",
    "    print(f\"âœ“ Loaded {len(islands)} islands\")\n",
    "    \n",
    "    print(\"â›½ Loading LNG terminal data...\")\n",
    "    # Read LNG terminal data\n",
    "    lng_terminals = pd.read_excel(\"../visualization/LNG_Terminals.xlsx\")\n",
    "    # Filter only operational terminals with valid coordinates\n",
    "    lng_active = lng_terminals[\n",
    "        (lng_terminals['Status'].isin(['Operating', 'Under Construction'])) &\n",
    "        (lng_terminals['Latitude'].notna()) & \n",
    "        (lng_terminals['Longitude'].notna())\n",
    "    ].copy()\n",
    "    lng_active['lon'] = lng_active['Longitude'] \n",
    "    lng_active['lat'] = lng_active['Latitude']\n",
    "    print(f\"âœ“ Loaded {len(lng_active)} active LNG terminals\")\n",
    "    \n",
    "    return islands, lng_active\n",
    "\n",
    "def calculate_min_distances(islands, lng_terminals):\n",
    "    \"\"\"Calculate minimum great circle distance from each island to nearest LNG terminal\"\"\"\n",
    "    print(\"ğŸ“ Calculating distances to nearest LNG terminals...\")\n",
    "    \n",
    "    min_distances = []\n",
    "    \n",
    "    for idx, island in islands.iterrows():\n",
    "        island_coord = (island['lat'], island['lon'])\n",
    "        \n",
    "        # Calculate distance to all LNG terminals\n",
    "        distances = []\n",
    "        for _, terminal in lng_terminals.iterrows():\n",
    "            terminal_coord = (terminal['lat'], terminal['lon'])\n",
    "            # Calculate great circle distance in km and multiply by 1.2\n",
    "            distance = great_circle(island_coord, terminal_coord).kilometers * 1.2\n",
    "            distances.append(distance)\n",
    "        \n",
    "        # Find minimum distance\n",
    "        min_distance = min(distances) if distances else float('inf')\n",
    "        min_distances.append(min_distance)\n",
    "        \n",
    "        if idx % 500 == 0:\n",
    "            print(f\"  Processed {idx}/{len(islands)} islands...\")\n",
    "    \n",
    "    islands['min_lng_distance'] = min_distances\n",
    "    print(f\"âœ“ Distance calculation complete. Range: {min(min_distances):.1f} - {max(min_distances):.1f} km\")\n",
    "    \n",
    "    return islands\n",
    "\n",
    "def visualize_island_lng_distances(islands, lng_terminals):\n",
    "    \"\"\"Create global map visualization with distance-based color coding\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Create Point geometries for islands\n",
    "    islands['geometry'] = islands.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    geo_islands = gpd.GeoDataFrame(islands, geometry='geometry')\n",
    "    geo_islands.set_crs(epsg=4326, inplace=True)\n",
    "    \n",
    "    # Create the figure with Robinson projection\n",
    "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "\n",
    "    # Set background and map features\n",
    "    ax.set_facecolor('#FFFFFF')  \n",
    "    ax.add_feature(cfeature.LAND, color=\"#CECECE\", alpha=0.4)\n",
    "    ax.add_feature(cfeature.OCEAN, color=\"#FFFFFF\", alpha=0.5)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Color mapping for islands based on distance to LNG\n",
    "    # Farther from LNG terminals = darker color\n",
    "    sci_colors = ['#012f48', '#669aba', '#fbf0d9', '#be1420', '#7a0101']\n",
    "    custom_cmap = mpl.colors.LinearSegmentedColormap.from_list('sci_palette', sci_colors)\n",
    "    \n",
    "    # Set distance range for color mapping\n",
    "    max_distance = np.percentile(geo_islands['min_lng_distance'], 95)  # Use 95th percentile to avoid outliers\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=max_distance)\n",
    "    \n",
    "    # Point sizes\n",
    "    min_size = 20\n",
    "    max_size = 200\n",
    "    \n",
    "    # Sort islands by distance (closest first, so farthest are on top)\n",
    "    geo_islands = geo_islands.sort_values(by='min_lng_distance')\n",
    "    \n",
    "    print(\"ğŸï¸ Drawing islands...\")\n",
    "    # Draw island points\n",
    "    for idx, row in geo_islands.iterrows():\n",
    "        lon, lat = row.geometry.x, row.geometry.y\n",
    "        distance = row['min_lng_distance']\n",
    "        \n",
    "        # Calculate size and color\n",
    "        size_factor = min(distance / max_distance, 1.0)\n",
    "        size = min_size + (size_factor * (max_size - min_size))\n",
    "        color = custom_cmap(norm(distance))\n",
    "        \n",
    "        # Create point image\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi=100)\n",
    "        temp_fig.patch.set_alpha(0)\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # Draw circle with black border\n",
    "        outer_circle = plt.Circle((0.5, 0.5), 0.18, color='black', alpha=1)\n",
    "        temp_ax.add_patch(outer_circle)\n",
    "        \n",
    "        inner_circle = plt.Circle((0.5, 0.5), 0.15, color=color, alpha=1)\n",
    "        temp_ax.add_patch(inner_circle)\n",
    "        \n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')\n",
    "        \n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        point_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # Transform coordinates and add to map\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        zoom_factor = np.sqrt(size) / 50\n",
    "        \n",
    "        imagebox = OffsetImage(point_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0, zorder=10)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    print(\"â›½ Drawing LNG terminals...\")\n",
    "    # Draw LNG terminals as squares\n",
    "    for _, terminal in lng_terminals.iterrows():\n",
    "        lon, lat = terminal['lon'], terminal['lat']\n",
    "        \n",
    "        # Create square marker for LNG terminals\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi=100)\n",
    "        temp_fig.patch.set_alpha(0)\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # Draw square\n",
    "        square = plt.Rectangle((0.3, 0.3), 0.4, 0.4, color=\"#D2AB7B\", alpha=1)\n",
    "        temp_ax.add_patch(square)\n",
    "        \n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')\n",
    "    \n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        terminal_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # Transform coordinates and add to map\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        zoom_factor = 0.12\n",
    "        \n",
    "        imagebox = OffsetImage(terminal_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0, zorder=5)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    # Create legend for islands and LNG terminals\n",
    "    island_patch = mpatches.Patch(color='#012f48', label='Islands (color by distance to LNG)')\n",
    "    lng_patch = mpatches.Patch(color='#D2AB7B', label='LNG Terminals')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(handles=[island_patch, lng_patch], \n",
    "              loc='lower left', \n",
    "              bbox_to_anchor=(0.02, 0.02), \n",
    "              frameon=True,\n",
    "              fontsize=12,\n",
    "            #   title='Legend',\n",
    "              title_fontsize=12)\n",
    "    \n",
    "    # Create colorbar for island distances\n",
    "    fake_scatter = ax.scatter([-1000], [-1000], c=[0], cmap=custom_cmap, \n",
    "                             vmin=0, vmax=max_distance, s=1)\n",
    "    \n",
    "    cbar = fig.colorbar(fake_scatter, ax=ax, orientation='horizontal', \n",
    "                       shrink=0.6, pad=0.05, aspect=50)\n",
    "    cbar.set_label('Distance to Nearest LNG Terminal (km)', fontsize=14)\n",
    "    \n",
    "    # Add title and finalize\n",
    "    # ax.set_title('Global Islands: Distance to Nearest LNG Terminals\\n(Darker = Farther from LNG)', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "    fig.text(0.42, 0.05, 'Global Islands: Distance to Nearest LNG Terminals\\n(Darker = Farther from LNG)', \n",
    "                    fontsize=9, style='italic', alpha=0.7)\n",
    "    ax.set_global()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nğŸ“Š Distance Statistics:\")\n",
    "    print(f\"   Average distance to LNG: {geo_islands['min_lng_distance'].mean():.1f} km\")\n",
    "    print(f\"   Median distance to LNG: {geo_islands['min_lng_distance'].median():.1f} km\")\n",
    "    print(f\"   Islands > 1000 km from LNG: {len(geo_islands[geo_islands['min_lng_distance'] > 1000])}\")\n",
    "    print(f\"   Islands > 5000 km from LNG: {len(geo_islands[geo_islands['min_lng_distance'] > 5000])}\")\n",
    "\n",
    "# Main execution\n",
    "print(\"ğŸš€ Starting global island-LNG distance analysis...\")\n",
    "islands, lng_terminals = load_island_lng_data()\n",
    "islands_with_distances = calculate_min_distances(islands, lng_terminals)\n",
    "visualize_island_lng_distances(islands_with_distances, lng_terminals)\n",
    "print(\"âœ… Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i5jhtm1gnwb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# 1. è¯»å–å²›å±¿æ•°æ®\n",
    "filtered_islands = pd.read_csv('../demand_get/filtered_island_1898.csv')\n",
    "print(f\"è¯»å–åˆ° {len(filtered_islands)} ä¸ªå²›å±¿\")\n",
    "\n",
    "# 2. è¯»å–IPCCåŒºåŸŸæ•°æ®\n",
    "ipcc_regions = gpd.read_file('../visualization/IPCC-WGI-reference-regions-v4.geojson')\n",
    "print(f\"è¯»å–åˆ° {len(ipcc_regions)} ä¸ªIPCCåŒºåŸŸ\")\n",
    "\n",
    "# 3. å°†å²›å±¿åæ ‡æ˜ å°„åˆ°IPCCåŒºåŸŸ\n",
    "def map_islands_to_ipcc_regions(islands_df, ipcc_regions):\n",
    "    \"\"\"å°†å²›å±¿åæ ‡æ˜ å°„åˆ°IPCCåŒºåŸŸ\"\"\"\n",
    "    island_region_mapping = []\n",
    "    \n",
    "    for idx, island in islands_df.iterrows():\n",
    "        lat, lon = island['Lat'], island['Long']\n",
    "        point = Point(lon, lat)  # æ³¨æ„ç»çº¬åº¦çš„é¡ºåº\n",
    "        \n",
    "        # æŸ¥æ‰¾åŒ…å«è¯¥ç‚¹çš„IPCCåŒºåŸŸ\n",
    "        region_found = False\n",
    "        for _, region in ipcc_regions.iterrows():\n",
    "            if region.geometry.contains(point):\n",
    "                island_region_mapping.append({\n",
    "                    'island_lat': lat,\n",
    "                    'island_lon': lon,\n",
    "                    'region_name': region['Name'],\n",
    "                    'region_acronym': region['Acronym'],\n",
    "                    'continent': region['Continent']\n",
    "                })\n",
    "                region_found = True\n",
    "                break\n",
    "        \n",
    "        if not region_found:\n",
    "            island_region_mapping.append({\n",
    "                'island_lat': lat,\n",
    "                'island_lon': lon,\n",
    "                'region_name': 'Unknown',\n",
    "                'region_acronym': 'UNK',\n",
    "                'continent': 'Unknown'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(island_region_mapping)\n",
    "\n",
    "print(\"æ­£åœ¨å°†å²›å±¿æ˜ å°„åˆ°IPCCåŒºåŸŸ...\")\n",
    "island_region_map = map_islands_to_ipcc_regions(filtered_islands, ipcc_regions)\n",
    "\n",
    "# 4. è®¡ç®—æ¯ä¸ªåŒºåŸŸçš„å²›å±¿æ•°é‡\n",
    "region_counts = island_region_map['region_acronym'].value_counts()\n",
    "print(\"\\nå„åŒºåŸŸå²›å±¿æ•°é‡ï¼š\")\n",
    "print(region_counts.head(15))\n",
    "\n",
    "# 5. ç­›é€‰è‡³å°‘æœ‰10ä¸ªå²›å±¿çš„åŒºåŸŸ\n",
    "valid_regions = region_counts[region_counts >= 10].index.tolist()\n",
    "print(f\"\\nè‡³å°‘æœ‰10ä¸ªå²›å±¿çš„åŒºåŸŸï¼š{valid_regions}\")\n",
    "\n",
    "# è¿‡æ»¤æ•°æ®åªä¿ç•™æœ‰æ•ˆåŒºåŸŸçš„å²›å±¿\n",
    "valid_islands = island_region_map[island_region_map['region_acronym'].isin(valid_regions)].copy()\n",
    "print(f\"æœ‰æ•ˆå²›å±¿æ•°é‡ï¼š{len(valid_islands)}\")\n",
    "\n",
    "# 6. è¯»å–æ¯ä¸ªå²›å±¿çš„å­˜å‚¨å®¹é‡æ•°æ®å¹¶è®¡ç®—åŒºåŸŸå¹³å‡å€¼\n",
    "def calculate_regional_storage_capacity(valid_islands):\n",
    "    \"\"\"è®¡ç®—æ¯ä¸ªæœ‰æ•ˆåŒºåŸŸçš„å¹³å‡å­˜å‚¨å®¹é‡\"\"\"\n",
    "    regional_storage = defaultdict(lambda: {'LNG': [], 'ESS': [], 'TES': [], 'CES': [], 'H2S': []})\n",
    "    \n",
    "    data_path = '../result'\n",
    "    capacity_file = 'island_capacity_0.csv'\n",
    "    capacity_file_path = os.path.join(data_path, capacity_file)\n",
    "    \n",
    "    if os.path.exists(capacity_file_path):\n",
    "        try:\n",
    "            # è¯»å–å®¹é‡æ•°æ®\n",
    "            capacity_data = pd.read_csv(capacity_file_path)\n",
    "            print(f\"âœ“ è¯»å–å®¹é‡æ•°æ®: {len(capacity_data)} æ¡è®°å½•\")\n",
    "            \n",
    "            # å‡è®¾capacity_dataåŒ…å«lat, lonåˆ—ç”¨äºåŒ¹é…å²›å±¿\n",
    "            if 'lat' in capacity_data.columns and 'lon' in capacity_data.columns:\n",
    "                # å°†å®¹é‡æ•°æ®ä¸å²›å±¿-åŒºåŸŸæ˜ å°„åˆå¹¶\n",
    "                for _, island in valid_islands.iterrows():\n",
    "                    lat, lon = island['island_lat'], island['island_lon']\n",
    "                    region_acronym = island['region_acronym']\n",
    "                    \n",
    "                    # æŸ¥æ‰¾åŒ¹é…çš„å®¹é‡æ•°æ®ï¼ˆå…è®¸ä¸€å®šè¯¯å·®ï¼‰\n",
    "                    tolerance = 0.01\n",
    "                    matches = capacity_data[\n",
    "                        (abs(capacity_data['lat'] - lat) < tolerance) & \n",
    "                        (abs(capacity_data['lon'] - lon) < tolerance)\n",
    "                    ]\n",
    "                    \n",
    "                    if len(matches) > 0:\n",
    "                        match = matches.iloc[0]\n",
    "                        # æ·»åŠ å­˜å‚¨å®¹é‡æ•°æ®\n",
    "                        storage_types = ['LNG', 'ESS', 'TES', 'CES', 'H2S']\n",
    "                        for storage_type in storage_types:\n",
    "                            if storage_type in match:\n",
    "                                regional_storage[region_acronym][storage_type].append(match[storage_type])\n",
    "                            else:\n",
    "                                regional_storage[region_acronym][storage_type].append(0)\n",
    "            else:\n",
    "                print(\"âš ï¸ å®¹é‡æ•°æ®ä¸­æ²¡æœ‰lat, lonåˆ—ï¼Œä½¿ç”¨éšæœºåˆ†å¸ƒ\")\n",
    "                # ä½¿ç”¨éšæœºæ–¹æ³•åˆ†é…å®¹é‡æ•°æ®åˆ°åŒºåŸŸ\n",
    "                storage_types = ['LNG', 'ESS', 'TES', 'CES', 'H2S']\n",
    "                total_capacity = capacity_data[storage_types].sum() if all(st in capacity_data.columns for st in storage_types) else None\n",
    "                \n",
    "                if total_capacity is not None:\n",
    "                    for _, island in valid_islands.iterrows():\n",
    "                        region_acronym = island['region_acronym']\n",
    "                        for storage_type in storage_types:\n",
    "                            # éšæœºåˆ†é…ä¸€éƒ¨åˆ†æ€»å®¹é‡ç»™è¿™ä¸ªå²›å±¿\n",
    "                            assigned_capacity = total_capacity[storage_type] * np.random.uniform(0.001, 0.01)\n",
    "                            regional_storage[region_acronym][storage_type].append(assigned_capacity)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"è¯»å–å®¹é‡æ–‡ä»¶æ—¶å‡ºé”™: {e}\")\n",
    "            regional_storage = create_mock_storage_data(valid_islands)\n",
    "    else:\n",
    "        print(\"âŒ å®¹é‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®\")\n",
    "        regional_storage = create_mock_storage_data(valid_islands)\n",
    "    \n",
    "    # è®¡ç®—æ¯ä¸ªåŒºåŸŸçš„å¹³å‡å€¼\n",
    "    region_avg_storage = []\n",
    "    for region, storage_data in regional_storage.items():\n",
    "        if storage_data['LNG']:  # å¦‚æœæœ‰æ•°æ®\n",
    "            avg_storage = {}\n",
    "            for storage_type in ['LNG', 'ESS', 'TES', 'CES', 'H2S']:\n",
    "                avg_storage[f'avg_{storage_type.lower()}_capacity'] = np.mean(storage_data[storage_type])\n",
    "            \n",
    "            region_avg_storage.append({\n",
    "                'region_acronym': region,\n",
    "                'avg_lng_capacity': avg_storage['avg_lng_capacity'],\n",
    "                'avg_ess_capacity': avg_storage['avg_ess_capacity'],\n",
    "                'avg_tes_capacity': avg_storage['avg_tes_capacity'],\n",
    "                'avg_ces_capacity': avg_storage['avg_ces_capacity'],\n",
    "                'avg_h2s_capacity': avg_storage['avg_h2s_capacity'],\n",
    "                'island_count': len(storage_data['LNG'])\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(region_avg_storage)\n",
    "\n",
    "def create_mock_storage_data(valid_islands):\n",
    "    \"\"\"åˆ›å»ºæ¨¡æ‹Ÿå­˜å‚¨æ•°æ®\"\"\"\n",
    "    regional_storage = defaultdict(lambda: {'LNG': [], 'ESS': [], 'TES': [], 'CES': [], 'H2S': []})\n",
    "    \n",
    "    for _, island in valid_islands.iterrows():\n",
    "        region_acronym = island['region_acronym']\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªå²›å±¿ç”Ÿæˆéšæœºå­˜å‚¨å®¹é‡\n",
    "        lng_cap = np.random.exponential(50)\n",
    "        ess_cap = np.random.exponential(30)\n",
    "        tes_cap = np.random.exponential(20)\n",
    "        ces_cap = np.random.exponential(15)\n",
    "        h2s_cap = np.random.exponential(10)\n",
    "        \n",
    "        regional_storage[region_acronym]['LNG'].append(lng_cap)\n",
    "        regional_storage[region_acronym]['ESS'].append(ess_cap)\n",
    "        regional_storage[region_acronym]['TES'].append(tes_cap)\n",
    "        regional_storage[region_acronym]['CES'].append(ces_cap)\n",
    "        regional_storage[region_acronym]['H2S'].append(h2s_cap)\n",
    "    \n",
    "    return regional_storage\n",
    "\n",
    "# 7. ä¸ºæ¯ä¸ªIPCCåŒºåŸŸå®šä¹‰å¯è§†åŒ–åæ ‡\n",
    "def get_predefined_region_coordinates():\n",
    "    \"\"\"ä¸ºæ¯ä¸ªIPCCåŒºåŸŸå®šä¹‰å›ºå®šçš„å¯è§†åŒ–åæ ‡ä½ç½®\"\"\"\n",
    "    region_coords = {\n",
    "        'CAR': (20.0, -60.0),   # Caribbean\n",
    "        'NAO': (40.0, -30.0),   # North Atlantic Ocean\n",
    "        'MED': (35.0, 20.0),    # Mediterranean\n",
    "        'SSA': (-50.0, -70.0),  # Southern South America\n",
    "        'NZ': (-40.0, 175.0),   # New Zealand\n",
    "        'EAS': (30.0, 120.0),   # East Asia\n",
    "        'SPO': (-40.0, -150.0), # South Pacific Ocean\n",
    "        'SEA': (0.0, 125.0),    # Southeast Asia\n",
    "        'NEU': (55.0, 10.0),    # Northern Europe\n",
    "        'GIC': (65.0, -40.0),   # Greenland/Iceland\n",
    "        'AUS': (-25.0, 135.0),  # Australia\n",
    "        'SAO': (-20.0, -10.0),  # South Atlantic Ocean\n",
    "        'SAS': (20.0, 80.0),    # South Asia\n",
    "        'WAS': (15.0, 45.0),    # West Asia\n",
    "        'CAS': (45.0, 70.0),    # Central Asia\n",
    "        'ENA': (45.0, -75.0),   # Eastern North America\n",
    "        'WNA': (45.0, -120.0),  # Western North America\n",
    "        'CNA': (35.0, -100.0),  # Central North America\n",
    "        'NEN': (65.0, 30.0),    # Northern Europe North\n",
    "        'WSA': (-10.0, -60.0),  # Western South America\n",
    "        'NSA': (-5.0, -55.0),   # Northern South America\n",
    "        'NES': (-15.0, -45.0),  # Northeast South America\n",
    "        'SAM': (-30.0, -60.0),  # South America\n",
    "        'WAF': (10.0, 0.0),     # West Africa\n",
    "        'CAF': (0.0, 20.0),     # Central Africa\n",
    "        'EAF': (0.0, 40.0),     # East Africa\n",
    "        'SAF': (-30.0, 25.0),   # Southern Africa\n",
    "        'MDG': (-20.0, 47.0),   # Madagascar\n",
    "        'ESB': (70.0, 120.0),   # East Siberia\n",
    "        'WSB': (65.0, 80.0),    # West Siberia\n",
    "        'RFE': (55.0, 135.0),   # Russian Far East\n",
    "        'RAR': (75.0, 105.0),   # Russian Arctic\n",
    "        'WCA': (40.0, -10.0),   # Western Central Africa\n",
    "        'ECA': (50.0, 20.0),    # Eastern Central Africa\n",
    "        'TIB': (32.0, 90.0),    # Tibet\n",
    "        'EEU': (55.0, 40.0),    # Eastern Europe\n",
    "        'SWS': (-40.0, -73.0),  # Southwest Scandinavia (ä¿®æ­£ä¸ºå—ç¾æ´²è¥¿å—éƒ¨)\n",
    "        'NWS': (70.0, 15.0),    # Northwest Scandinavia\n",
    "        'CEU': (50.0, 15.0),    # Central Europe\n",
    "        'WCE': (45.0, 5.0),     # West Central Europe\n",
    "        'ECE': (50.0, 25.0),    # East Central Europe\n",
    "        'MES': (30.0, 50.0),    # Middle East South\n",
    "        'MEN': (35.0, 35.0),    # Middle East North\n",
    "        'ARO': (75.0, 0.0),     # Arctic Ocean\n",
    "        'BOB': (15.0, 90.0),    # Bay of Bengal\n",
    "        'ARS': (15.0, 50.0),    # Arabian Sea\n",
    "        'SCS': (15.0, 115.0),   # South China Sea\n",
    "        'IOD': (-15.0, 75.0),   # Indian Ocean Dipole\n",
    "        'WIO': (-15.0, 60.0),   # Western Indian Ocean\n",
    "        'EIO': (-15.0, 90.0),   # Eastern Indian Ocean\n",
    "        'SIO': (-35.0, 75.0),   # Southern Indian Ocean\n",
    "        'EPO': (-10.0, -120.0), # Eastern Pacific Ocean\n",
    "        'NPO': (30.0, -150.0),  # North Pacific Ocean\n",
    "        'ARP': (15.0, 50.0),    # Arabian Peninsula\n",
    "        'SAH': (25.0, 10.0),    # Sahara\n",
    "        'SCA': (10.0, -85.0),   # Southern Central America\n",
    "        'NWN': (60.0, -140.0),  # Northwest North America\n",
    "        'NAU': (-15.0, 135.0),  # Northern Australia\n",
    "    }\n",
    "    \n",
    "    return region_coords\n",
    "\n",
    "def apply_predefined_coordinates(regional_storage_data):\n",
    "    \"\"\"ä¸ºæœ‰æ•ˆåŒºåŸŸåº”ç”¨é¢„å®šä¹‰çš„å¯è§†åŒ–åæ ‡\"\"\"\n",
    "    predefined_coords = get_predefined_region_coordinates()\n",
    "    \n",
    "    region_coords_list = []\n",
    "    for _, region_data in regional_storage_data.iterrows():\n",
    "        region_acronym = region_data['region_acronym']\n",
    "        \n",
    "        if region_acronym in predefined_coords:\n",
    "            lat, lon = predefined_coords[region_acronym]\n",
    "            region_coords_list.append({\n",
    "                'region_acronym': region_acronym,\n",
    "                'center_lat': lat,\n",
    "                'center_lon': lon\n",
    "            })\n",
    "        else:\n",
    "            # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰åæ ‡ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®\n",
    "            print(f\"è­¦å‘Š: åŒºåŸŸ {region_acronym} æ²¡æœ‰é¢„å®šä¹‰åæ ‡ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®\")\n",
    "            region_coords_list.append({\n",
    "                'region_acronym': region_acronym,\n",
    "                'center_lat': 0.0,\n",
    "                'center_lon': 0.0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(region_coords_list)\n",
    "\n",
    "def create_ipcc_regional_storage_pie_chart(final_storage_data):\n",
    "    \"\"\"åŸºäºIPCCåŒºåŸŸæ•°æ®åˆ›å»ºå­˜å‚¨å®¹é‡é¥¼çŠ¶å›¾å¯è§†åŒ–\"\"\"\n",
    "    \n",
    "    # è®¡ç®—æ€»å®¹é‡å¹¶æŒ‰æ€»å®¹é‡æ’åºï¼Œç¡®ä¿å°é¥¼å›¾å…ˆç”»ï¼Œä¸ä¼šè¢«å¤§é¥¼å›¾è¦†ç›–\n",
    "    final_storage_data['total_capacity'] = (\n",
    "        final_storage_data['avg_lng_capacity'] + \n",
    "        final_storage_data['avg_ess_capacity'] +\n",
    "        final_storage_data['avg_tes_capacity'] + \n",
    "        final_storage_data['avg_ces_capacity'] +\n",
    "        final_storage_data['avg_h2s_capacity']\n",
    "    )\n",
    "    df_sorted = final_storage_data.sort_values(by='total_capacity', ascending=True)\n",
    "    \n",
    "    # åˆ›å»ºå¸¦æœ‰ cartopy æŠ•å½±çš„å›¾å½¢\n",
    "    fig = plt.figure(figsize=(16, 10), dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "    \n",
    "    # è®¾ç½®èƒŒæ™¯å’Œåœ°å›¾ç‰¹å¾\n",
    "    ax.set_global()\n",
    "    ax.add_feature(cfeature.LAND, facecolor='#E0E0E0', zorder=0)\n",
    "    ax.add_feature(cfeature.OCEAN, facecolor='#FFFFFF', zorder=0)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7, zorder=1)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.6, zorder=1)\n",
    "    \n",
    "    # å®šä¹‰é¥¼å›¾çš„å±æ€§\n",
    "    colors = ['#808080', '#1f77b4', '#ff7f0e', '#aec7e8', '#98df8a']\n",
    "    storage_types = ['LNG', 'ESS', 'TES', 'CES', 'H2S']\n",
    "    storage_columns = ['avg_lng_capacity', 'avg_ess_capacity', 'avg_tes_capacity', 'avg_ces_capacity', 'avg_h2s_capacity']\n",
    "    \n",
    "    # åŠ¨æ€è°ƒæ•´å¤§å°çš„å‚æ•°\n",
    "    base_zoom = 0.08  # é¥¼å›¾çš„åŸºç¡€ç¼©æ”¾æ¯”ä¾‹\n",
    "    scale_factor = 0.00005  # å®¹é‡å¯¹å¤§å°çš„å½±å“å› å­\n",
    "    \n",
    "    # éå†æ¯ä¸ªåŒºåŸŸæ¥ç»˜åˆ¶é¥¼å›¾\n",
    "    for index, row in df_sorted.iterrows():\n",
    "        lat, lon = row['center_lat'], row['center_lon']\n",
    "        total_capacity = row['total_capacity']\n",
    "        region_name = row['region_acronym']\n",
    "        island_count = row['island_count']\n",
    "        \n",
    "        # å¦‚æœæ€»å®¹é‡ä¸º0ï¼Œåˆ™è·³è¿‡\n",
    "        if total_capacity <= 0:\n",
    "            continue\n",
    "        \n",
    "        # è·å–å„å­˜å‚¨ç±»å‹çš„å®¹é‡\n",
    "        capacities = [row[col] for col in storage_columns]\n",
    "        \n",
    "        # è¿‡æ»¤æ‰0å€¼ï¼Œé¿å…ç©ºé¥¼å—\n",
    "        non_zero_capacities = []\n",
    "        non_zero_colors = []\n",
    "        \n",
    "        for i, cap in enumerate(capacities):\n",
    "            if cap > 0:\n",
    "                non_zero_capacities.append(cap)\n",
    "                non_zero_colors.append(colors[i])\n",
    "        \n",
    "        if not non_zero_capacities:  # å¦‚æœæ²¡æœ‰éé›¶å®¹é‡\n",
    "            continue\n",
    "            \n",
    "        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ã€é€æ˜çš„ç”»å¸ƒæ¥ç”Ÿæˆé¥¼å›¾å›¾åƒ\n",
    "        fig_temp, ax_temp = plt.subplots(figsize=(2, 2), dpi=150)\n",
    "        fig_temp.patch.set_alpha(0)  # å›¾çª—èƒŒæ™¯é€æ˜\n",
    "        ax_temp.patch.set_alpha(0)   # åæ ‡è½´èƒŒæ™¯é€æ˜\n",
    "        \n",
    "        # åœ¨ä¸´æ—¶åæ ‡è½´ä¸Šç»˜åˆ¶é¥¼å›¾\n",
    "        wedges, texts = ax_temp.pie(\n",
    "            non_zero_capacities,\n",
    "            colors=non_zero_colors,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},\n",
    "            startangle=90\n",
    "        )\n",
    "        ax_temp.set_aspect('equal')  # ä¿è¯æ˜¯åœ†å½¢\n",
    "        ax_temp.axis('off')  # å…³é—­åæ ‡è½´æ˜¾ç¤º\n",
    "        fig_temp.tight_layout(pad=0)  # å»é™¤ç™½è¾¹\n",
    "        \n",
    "        # å°†ç»˜åˆ¶å¥½çš„é¥¼å›¾æ¸²æŸ“æˆä¸€ä¸ªNumpyæ•°ç»„å›¾åƒ\n",
    "        fig_temp.canvas.draw()\n",
    "        pie_img = np.array(fig_temp.canvas.renderer.buffer_rgba())\n",
    "        plt.close(fig_temp)  # å…³é—­ä¸´æ—¶å›¾åƒï¼Œé‡Šæ”¾å†…å­˜\n",
    "        \n",
    "        # è®¡ç®—é¥¼å›¾çš„åŠ¨æ€å¤§å° (ç¼©æ”¾æ¯”ä¾‹)\n",
    "        zoom = base_zoom + scale_factor * total_capacity\n",
    "        zoom = max(0.05, min(zoom, 0.25))  # é™åˆ¶ç¼©æ”¾èŒƒå›´\n",
    "        \n",
    "        # å°†é¥¼å›¾å›¾åƒä½œä¸ºOffsetImageæ·»åŠ åˆ°ä¸»åœ°å›¾ä¸Š\n",
    "        # å°†åœ°ç†åæ ‡è½¬æ¢ä¸ºåœ°å›¾æŠ•å½±åæ ‡\n",
    "        point_in_map_proj = ax.projection.transform_point(lon, lat, ccrs.Geodetic())\n",
    "        \n",
    "        # åˆ›å»ºå›¾åƒç›’å­\n",
    "        imagebox = OffsetImage(pie_img, zoom=zoom)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        # ä½¿ç”¨AnnotationBboxå°†å›¾åƒç›’å­ç²¾ç¡®æ”¾ç½®åœ¨åœ°å›¾ä¸Š\n",
    "        ab = AnnotationBbox(\n",
    "            imagebox,\n",
    "            point_in_map_proj,\n",
    "            frameon=False,\n",
    "            pad=0\n",
    "        )\n",
    "        ax.add_artist(ab)\n",
    "        \n",
    "        # åœ¨é¥¼å›¾æ—è¾¹æ ‡æ³¨åŒºåŸŸåç§°\n",
    "        label_text = f\"{region_name}\"\n",
    "        \n",
    "        # æ ¹æ®ä½ç½®è°ƒæ•´æ ‡ç­¾ä½ç½®\n",
    "        offset_lon = 5 if lon < 0 else -5\n",
    "        offset_lat = -5 if lat > 0 else 5\n",
    "        \n",
    "        ax.text(lon + offset_lon,\n",
    "                lat + offset_lat,\n",
    "                label_text,\n",
    "                transform=ccrs.Geodetic(),\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                zorder=11,\n",
    "                fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\",\n",
    "                          facecolor=\"white\", \n",
    "                          edgecolor=\"gray\",\n",
    "                          alpha=0.8))\n",
    "    \n",
    "    # åˆ›å»ºå›¾ä¾‹\n",
    "    legend_patches = []\n",
    "    for i, storage_type in enumerate(storage_types):\n",
    "        legend_patches.append(mpatches.Patch(color=colors[i], label=storage_type))\n",
    "    \n",
    "    ax.legend(handles=legend_patches, \n",
    "              loc='lower left', \n",
    "              bbox_to_anchor=(0.02, 0.02), \n",
    "              frameon=True,\n",
    "              fontsize=12)\n",
    "    \n",
    "    # æ·»åŠ æ ‡é¢˜\n",
    "    # ax.set_title('Global Island Storage Capacity Distribution by IPCC Regions', \n",
    "    #             fontsize=14, pad=15)\n",
    "    \n",
    "    # ç§»é™¤è¾¹æ¡†\n",
    "    plt.setp(ax.spines.values(), visible=False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# æ‰§è¡Œå­˜å‚¨å®¹é‡æ•°æ®å¤„ç†å’Œå¯è§†åŒ–\n",
    "print(\"\\næ­£åœ¨è®¡ç®—å„åŒºåŸŸçš„å¹³å‡å­˜å‚¨å®¹é‡...\")\n",
    "regional_storage_data = calculate_regional_storage_capacity(valid_islands)\n",
    "\n",
    "if len(regional_storage_data) > 0:\n",
    "    print(\"\\nå„åŒºåŸŸå¹³å‡å­˜å‚¨å®¹é‡æ•°æ®ï¼š\")\n",
    "    print(regional_storage_data)\n",
    "    \n",
    "    # åº”ç”¨é¢„å®šä¹‰åæ ‡\n",
    "    storage_coordinates = apply_predefined_coordinates(regional_storage_data)\n",
    "    \n",
    "    # åˆå¹¶æ•°æ®ç”¨äºå¯è§†åŒ–\n",
    "    final_storage_data = regional_storage_data.merge(storage_coordinates, on='region_acronym')\n",
    "    \n",
    "    print(\"\\næœ€ç»ˆå­˜å‚¨æ•°æ®ï¼ˆåŒ…å«é¢„å®šä¹‰åæ ‡ï¼‰ï¼š\")\n",
    "    print(final_storage_data[['region_acronym', 'avg_lng_capacity', 'avg_ess_capacity', \n",
    "                             'avg_tes_capacity', 'avg_ces_capacity', 'avg_h2s_capacity', 'island_count']])\n",
    "    \n",
    "    # åˆ›å»ºå­˜å‚¨å®¹é‡å¯è§†åŒ–å›¾è¡¨\n",
    "    print(\"\\næ­£åœ¨åˆ›å»ºIPCCåŒºåŸŸå¹³å‡å­˜å‚¨å®¹é‡é¥¼çŠ¶å›¾...\")\n",
    "    fig_storage = create_ipcc_regional_storage_pie_chart(final_storage_data)\n",
    "    print(\"\\nå­˜å‚¨å®¹é‡å¯è§†åŒ–å®Œæˆï¼\")\n",
    "    \n",
    "    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n=== å­˜å‚¨å®¹é‡ç»Ÿè®¡ä¿¡æ¯ ===\")\n",
    "    print(f\"æœ‰æ•ˆIPCCåŒºåŸŸæ•°é‡: {len(final_storage_data)}\")\n",
    "    print(f\"åŒ…å«çš„å²›å±¿æ€»æ•°: {final_storage_data['island_count'].sum()}\")\n",
    "    print(f\"å¹³å‡æ¯åŒºåŸŸå²›å±¿æ•°: {final_storage_data['island_count'].mean():.1f}\")\n",
    "    \n",
    "    # è®¡ç®—å„å­˜å‚¨ç±»å‹çš„æ€»å®¹é‡\n",
    "    total_lng = final_storage_data['avg_lng_capacity'].sum()\n",
    "    total_ess = final_storage_data['avg_ess_capacity'].sum()\n",
    "    total_tes = final_storage_data['avg_tes_capacity'].sum()\n",
    "    total_ces = final_storage_data['avg_ces_capacity'].sum()\n",
    "    total_h2s = final_storage_data['avg_h2s_capacity'].sum()\n",
    "    grand_total = total_lng + total_ess + total_tes + total_ces + total_h2s\n",
    "    \n",
    "    print(f\"\\nå„å­˜å‚¨ç±»å‹æ€»å®¹é‡:\")\n",
    "    print(f\"LNG: {total_lng:.1f} ({total_lng/grand_total*100:.1f}%)\")\n",
    "    print(f\"ESS: {total_ess:.1f} ({total_ess/grand_total*100:.1f}%)\")\n",
    "    print(f\"TES: {total_tes:.1f} ({total_tes/grand_total*100:.1f}%)\")\n",
    "    print(f\"CES: {total_ces:.1f} ({total_ces/grand_total*100:.1f}%)\")\n",
    "    print(f\"H2S: {total_h2s:.1f} ({total_h2s/grand_total*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åŒºåŸŸå­˜å‚¨å®¹é‡æ•°æ®ï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "island",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
