{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy.interpolate import make_interp_spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31001b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and prepare GDP matching using fuzzy matching\n",
    "from difflib import get_close_matches\n",
    "import re\n",
    "\n",
    "cost_columns = [\"total_cost_0\",\"total_cost_2020\",\"total_cost_2050\"]\n",
    "df = pd.read_csv('output_scenario.csv')\n",
    "\n",
    "# Load GDP data\n",
    "gdp_df = pd.read_csv('gdp.csv')\n",
    "\n",
    "# Extract 2020 GDP per capita data\n",
    "gdp_2020 = gdp_df[['Country Name', '2020']].copy()\n",
    "gdp_2020.columns = ['Country', 'GDP_per_capita_2020']\n",
    "gdp_2020['GDP_per_capita_2020'] = pd.to_numeric(gdp_2020['GDP_per_capita_2020'], errors='coerce')\n",
    "\n",
    "# Clean country names function\n",
    "def clean_country_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    # Remove extra spaces and convert to lowercase\n",
    "    name = str(name).strip().lower()\n",
    "    # Remove common prefixes/suffixes\n",
    "    name = re.sub(r'\\b(republic of|kingdom of|state of|federation of)\\b', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "# Function to fuzzy match country names\n",
    "def fuzzy_match_country(country, gdp_countries, threshold=0.6):\n",
    "    if pd.isna(country):\n",
    "        return None\n",
    "    \n",
    "    # Handle multiple countries (separated by semicolon)\n",
    "    if ';' in str(country):\n",
    "        countries = [c.strip() for c in str(country).split(';')]\n",
    "        country = countries[0]  # Use first country\n",
    "    \n",
    "    # Clean the country name\n",
    "    clean_country = clean_country_name(country)\n",
    "    if not clean_country:\n",
    "        return None\n",
    "    \n",
    "    # Clean GDP country names for matching\n",
    "    clean_gdp_countries = [clean_country_name(c) for c in gdp_countries]\n",
    "    clean_to_original = dict(zip(clean_gdp_countries, gdp_countries))\n",
    "    \n",
    "    # Try exact match first\n",
    "    if clean_country in clean_gdp_countries:\n",
    "        return clean_to_original[clean_country]\n",
    "    \n",
    "    # Use fuzzy matching\n",
    "    matches = get_close_matches(clean_country, clean_gdp_countries, n=1, cutoff=threshold)\n",
    "    if matches:\n",
    "        return clean_to_original[matches[0]]\n",
    "    \n",
    "    # Try partial matching for common cases\n",
    "    for clean_gdp, orig_gdp in clean_to_original.items():\n",
    "        if clean_country in clean_gdp or clean_gdp in clean_country:\n",
    "            return orig_gdp\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Match countries using fuzzy matching\n",
    "gdp_countries = list(gdp_2020['Country'].dropna())\n",
    "df['GDP_Country'] = df['Country'].apply(lambda x: fuzzy_match_country(x, gdp_countries))\n",
    "\n",
    "# Merge GDP data\n",
    "df = df.merge(gdp_2020[['Country', 'GDP_per_capita_2020']], \n",
    "              left_on='GDP_Country', right_on='Country', \n",
    "              how='left', suffixes=('', '_gdp'))\n",
    "\n",
    "# Calculate per capita costs (cost per person)\n",
    "df[cost_columns] = df[cost_columns].div(df['pop'], axis=0)\n",
    "\n",
    "# Calculate EIBC (cost/GDP) - only where GDP data is available\n",
    "df['EIBC_0'] = df['total_cost_0'] / df['GDP_per_capita_2020']\n",
    "df['EIBC_2020'] = df['total_cost_2020'] / df['GDP_per_capita_2020']\n",
    "df['EIBC_2050'] = df['total_cost_2050'] / df['GDP_per_capita_2020']\n",
    "\n",
    "print(f\"Successfully matched GDP data for {df['GDP_per_capita_2020'].notna().sum()} out of {len(df)} countries\")\n",
    "print(f\"Countries with missing GDP data: {df[df['GDP_per_capita_2020'].isna()]['Country'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cost(data, vmax, column):\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    # 导入必要的模块\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "    import numpy as np\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    \n",
    "    # 创建Point几何图形\n",
    "    data['geometry'] = data.apply(lambda row: Point(row['Long'], row['Lat']), axis=1)\n",
    "    geo_df = gpd.GeoDataFrame(data, geometry='geometry')\n",
    "    geo_df.set_crs(epsg=4326, inplace=True)\n",
    "    \n",
    "    # 创建带有cartopy投影的图形\n",
    "    fig = plt.figure(figsize=(14, 6), dpi=500)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "\n",
    "    # 设置背景和地图特征\n",
    "    ax.set_facecolor(\"#FFFEFE\")  \n",
    "    ax.add_feature(cfeature.LAND, color=\"#CECECE\", alpha=0.4)\n",
    "    ax.add_feature(cfeature.OCEAN, color=\"#FFFFFF\", alpha=0.5)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # 使用更简单的方法创建密度图\n",
    "    resolution = 1.0  # 1度分辨率\n",
    "    lons = np.arange(-180, 181, resolution)\n",
    "    lats = np.arange(-90, 91, resolution)\n",
    "    \n",
    "    # 创建网格点\n",
    "    lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "    density_grid = np.zeros_like(lon_grid)\n",
    "    \n",
    "    # 提取所有点的经纬度和值\n",
    "    all_lons = geo_df.geometry.x.values\n",
    "    all_lats = geo_df.geometry.y.values\n",
    "    all_values = geo_df[column].values\n",
    "    \n",
    "    # 使用更适合地理数据的影响半径\n",
    "    bandwidth = 3.0\n",
    "    \n",
    "    # 计算每个网格点的密度值\n",
    "    for i, row in enumerate(all_lons):\n",
    "        lon, lat = all_lons[i], all_lats[i]\n",
    "        value = all_values[i]\n",
    "        \n",
    "        # 计算此数据点对网格的影响\n",
    "        for x in range(len(lats)):\n",
    "            for y in range(len(lons)):\n",
    "                grid_lon = lons[y]\n",
    "                grid_lat = lats[x]\n",
    "                \n",
    "                # 计算距离\n",
    "                dist = np.sqrt((grid_lon - lon)**2 + (grid_lat - lat)**2)\n",
    "                \n",
    "                # 只在一定半径内影响网格点\n",
    "                if dist <= 3 * bandwidth:\n",
    "                    # 使用高斯核计算权重\n",
    "                    weight = np.exp(-0.5 * (dist / bandwidth)**2) * value\n",
    "                    density_grid[x, y] += weight\n",
    "    \n",
    "    # 对密度图应用轻微的高斯平滑\n",
    "    density_grid = gaussian_filter(density_grid, sigma=1.0)\n",
    "    \n",
    "    # 设置阈值，只在密度足够高的区域绘制斜线\n",
    "    threshold = np.max(density_grid) * 0.08\n",
    "    mask = density_grid < threshold\n",
    "    \n",
    "    # 设置上限值，避免极端值影响色彩分布\n",
    "    # 使用百分位数而不是最大值来设置上限，避免离群值的影响\n",
    "    upper_limit = np.percentile(density_grid[~mask], 90)  # 使用90%分位数作为上限\n",
    "    \n",
    "    # 裁剪过高的值\n",
    "    density_grid_capped = np.clip(density_grid, 0, upper_limit)\n",
    "    \n",
    "    # 创建掩码数组\n",
    "    density_grid_masked = np.ma.array(density_grid_capped, mask=mask)\n",
    "    \n",
    "    # 热力图颜色 - 使用更多颜色变化\n",
    "    heatmap_colors = ['#012f4830', '#669aba40', '#fbf0d950', '#be142060', '#7a010170']\n",
    "    heatmap_cmap = mpl.colors.LinearSegmentedColormap.from_list('heatmap_palette', heatmap_colors)\n",
    "    \n",
    "    # 创建自定义规范化对象，确保色彩分布均匀\n",
    "    heatmap_norm = mpl.colors.Normalize(vmin=threshold, vmax=upper_limit)\n",
    "    \n",
    "    # 绘制密度图 - 只在有数据的区域绘制斜线\n",
    "    contour = ax.contourf(\n",
    "        lon_grid, lat_grid, density_grid_masked,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        cmap=heatmap_cmap,\n",
    "        norm=heatmap_norm,  # 使用自定义规范化\n",
    "        levels=8,\n",
    "        alpha=0.7,\n",
    "        zorder=2,\n",
    "        # hatches=['/////', '/////', '/////', '/////', '/////', '/////', '/////', '/////'],\n",
    "        extend='neither'\n",
    "    )\n",
    "    \n",
    "    # 设置颜色映射\n",
    "    sci_colors = ['#012f48', '#669aba', '#fbf0d9', '#be1420', '#7a0101']  # From blue to red\n",
    "    custom_cmap = mpl.colors.LinearSegmentedColormap.from_list('sci_palette', sci_colors)\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=vmax)\n",
    "    \n",
    "    # 计算点大小范围\n",
    "    min_size = 20\n",
    "    max_size = 50\n",
    "    \n",
    "    # 对数据按值排序，保证小值在下层，大值在上层\n",
    "    geo_df = geo_df.sort_values(by=column)\n",
    "    \n",
    "    # 创建一个假散点用于颜色条\n",
    "    fake_scatter = ax.scatter(\n",
    "        [-1000], [-1000],  # 不可见位置\n",
    "        c=[0],\n",
    "        cmap=custom_cmap,\n",
    "        vmin=0,\n",
    "        vmax=vmax,\n",
    "        s=1\n",
    "    )\n",
    "    \n",
    "    # 为每个点创建并添加标记\n",
    "    for idx, row in geo_df.iterrows():\n",
    "        # 获取经纬度和值\n",
    "        lon, lat = row.geometry.x, row.geometry.y\n",
    "        value = row[column]\n",
    "        \n",
    "        # 计算点大小\n",
    "        size = min_size + ((value / vmax) * (max_size - min_size))\n",
    "        \n",
    "        # 计算颜色\n",
    "        color = custom_cmap(norm(value))\n",
    "        \n",
    "        # 创建临时图形来生成点图像\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi= 300)\n",
    "        temp_fig.patch.set_alpha(0)  # 透明背景\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # 先绘制一个稍大的黑色圆作为边框\n",
    "        outer_circle = plt.Circle(\n",
    "            (0.5, 0.5),\n",
    "            0.18,         # 稍大的半径\n",
    "            color='black',  # 黑色\n",
    "            alpha=1\n",
    "        )\n",
    "        temp_ax.add_patch(outer_circle)\n",
    "\n",
    "        # 再绘制一个内圆作为主要颜色区域\n",
    "        inner_circle = plt.Circle(\n",
    "            (0.5, 0.5),\n",
    "            0.15,         # 稍小的半径\n",
    "            color=color,  # 数据颜色\n",
    "            alpha=1\n",
    "        )\n",
    "        temp_ax.add_patch(inner_circle)\n",
    "        \n",
    "        # 设置坐标轴范围\n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')  # 隐藏坐标轴\n",
    "        \n",
    "        # 渲染并获取图像\n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        point_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # 将地理坐标转换为投影坐标\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # 计算缩放因子 - 调整点大小\n",
    "        zoom_factor = np.sqrt(size) / 100\n",
    "        \n",
    "        # 创建OffsetImage\n",
    "        imagebox = OffsetImage(point_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        # 创建并添加AnnotationBbox\n",
    "        ab = AnnotationBbox(\n",
    "            imagebox,\n",
    "            (x, y),\n",
    "            frameon=False,\n",
    "            pad=0,\n",
    "            zorder=10  # 确保点在最上层\n",
    "        )\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = fig.colorbar(\n",
    "        fake_scatter,\n",
    "        ax=ax,\n",
    "        orientation='horizontal',\n",
    "        shrink=0.6,  # 控制颜色条长度\n",
    "        pad=0.03,    # 调整颜色条和图形之间的间距\n",
    "        aspect=50    # 控制颜色条的宽度（值越小越宽）\n",
    "    )\n",
    "    cbar.set_label(f'Per Capita Investment Growth Rate', fontsize=12)\n",
    "    \n",
    "    # 设置全球边界\n",
    "    ax.set_global()\n",
    "     \n",
    "    # 移除坐标轴刻度和边框\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    plt.axis('off')  # 完全关闭坐标轴\n",
    "    \n",
    "    # 减少边距\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da796a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_longitude_profile(data, column, ax=None):\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \"\"\"创建经度方向的曲线图\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(14, 1),dpi=500)\n",
    "    \n",
    "    # 按经度分组计算平均值\n",
    "    lon_bins = np.arange(-180, 181, 5)  # 5度一组\n",
    "    lon_centers = (lon_bins[:-1] + lon_bins[1:]) / 2\n",
    "    lon_values = []\n",
    "    \n",
    "    for i in range(len(lon_bins)-1):\n",
    "        mask = (data['lon'] >= lon_bins[i]) & (data['lon'] < lon_bins[i+1])\n",
    "        if mask.any():\n",
    "            lon_values.append(data.loc[mask, column].mean())\n",
    "        else:\n",
    "            lon_values.append(0)  # 用0代替NaN\n",
    "    \n",
    "    # 平滑曲线\n",
    "    if len(lon_centers) > 3:\n",
    "        lon_smooth = np.linspace(min(lon_centers), max(lon_centers), 300)\n",
    "        spline = make_interp_spline(lon_centers, lon_values, k=3)\n",
    "        lon_values_smooth = spline(lon_smooth)\n",
    "        # 确保没有负值\n",
    "        lon_values_smooth = np.maximum(lon_values_smooth, 0)\n",
    "    else:\n",
    "        lon_smooth = lon_centers\n",
    "        lon_values_smooth = lon_values\n",
    "    \n",
    "    # 绘制曲线\n",
    "    ax.plot(lon_smooth, lon_values_smooth, color='#7a0101', linewidth=1.5)\n",
    "    ax.fill_between(lon_smooth, 0, lon_values_smooth, alpha=0.3, color=\"#a37070\")\n",
    "    \n",
    "    # 设置范围和网格线\n",
    "    ax.set_xlim(-180, 180)\n",
    "    ax.set_ylim(0, None)\n",
    "    \n",
    "    # 添加网格线\n",
    "    # ax.axvline(x=0, color='gray', linestyle='-', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axvline(x=60, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axvline(x=120, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axvline(x=-60, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axvline(x=-120, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    # 添加经度标签\n",
    "    # ax.text(0, -0.05, \"0°\", transform=ax.transData, ha='center', va='top', fontsize=8)\n",
    "    # ax.text(60, -0.05, \"60°E\", transform=ax.transData, ha='center', va='top', fontsize=8)\n",
    "    # ax.text(120, -0.05, \"120°E\", transform=ax.transData, ha='center', va='top', fontsize=8)\n",
    "    # ax.text(-60, -0.05, \"60°W\", transform=ax.transData, ha='center', va='top', fontsize=8)\n",
    "    # ax.text(-120, -0.05, \"120°W\", transform=ax.transData, ha='center', va='top', fontsize=8)\n",
    "    \n",
    "    # 美化图表\n",
    "    ax.set_xticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    # ax.set_ylabel('Avg. Investment', fontsize=9)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def create_latitude_profile(data, column, ax=None):\n",
    "    \"\"\"创建纬度方向的曲线图\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(2, 10),dpi=500)\n",
    "    \n",
    "    # 按纬度分组计算平均值\n",
    "    lat_bins = np.arange(-90, 91, 2)  # 2度一组\n",
    "    lat_centers = (lat_bins[:-1] + lat_bins[1:]) / 2\n",
    "    lat_values = []\n",
    "    \n",
    "    for i in range(len(lat_bins)-1):\n",
    "        mask = (data['lat'] >= lat_bins[i]) & (data['lat'] < lat_bins[i+1])\n",
    "        if mask.any():\n",
    "            lat_values.append(data.loc[mask, column].mean())\n",
    "        else:\n",
    "            lat_values.append(0)  # 用0代替NaN\n",
    "    \n",
    "    # 平滑曲线\n",
    "    if len(lat_centers) > 3:\n",
    "        lat_smooth = np.linspace(min(lat_centers), max(lat_centers), 300)\n",
    "        spline = make_interp_spline(lat_centers, lat_values, k=3)\n",
    "        lat_values_smooth = spline(lat_smooth)\n",
    "        # 确保没有负值\n",
    "        lat_values_smooth = np.maximum(lat_values_smooth, 0)\n",
    "    else:\n",
    "        lat_smooth = lat_centers\n",
    "        lat_values_smooth = lat_values\n",
    "    \n",
    "    # 绘制曲线\n",
    "    ax.plot(lat_values_smooth, lat_smooth, color='#7a0101', linewidth=1.5)\n",
    "    ax.fill_betweenx(lat_smooth, 0, lat_values_smooth, alpha=0.3, color='#a37070')\n",
    "    \n",
    "    # 设置范围和网格线\n",
    "    ax.set_ylim(-90, 90)\n",
    "    ax.set_xlim(0, None)\n",
    "    \n",
    "    # 添加网格线\n",
    "    # ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axhline(y=30, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axhline(y=60, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axhline(y=-30, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    # ax.axhline(y=-60, color='gray', linestyle='--', alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    # 添加纬度标签\n",
    "    # ax.text(-0.05, 0, \"0°\", transform=ax.transData, ha='right', va='center', fontsize=8)\n",
    "    # ax.text(-0.05, 30, \"30°N\", transform=ax.transData, ha='right', va='center', fontsize=8)\n",
    "    # ax.text(-0.05, 60, \"60°N\", transform=ax.transData, ha='right', va='center', fontsize=8)\n",
    "    # ax.text(-0.05, -30, \"30°S\", transform=ax.transData, ha='right', va='center', fontsize=8)\n",
    "    # ax.text(-0.05, -60, \"60°S\", transform=ax.transData, ha='right', va='center', fontsize=8)\n",
    "    \n",
    "    # 美化图表\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # ax.set_xlabel('Avg. Investment', fontsize=9)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc341be",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_longitude_profile(df, 'EIBC_0', ax=None)\n",
    "create_latitude_profile(df, 'EIBC_0', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate EIBC visualizations for 2020 and 2050\n",
    "def visualize_eibc_single(data, year, column, vmax=None):\n",
    "    \"\"\"Create individual EIBC visualization for a specific year\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "    import numpy as np\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    \n",
    "    # Filter data with valid EIBC values\n",
    "    data_valid = data.dropna(subset=[column])\n",
    "    \n",
    "    if len(data_valid) == 0:\n",
    "        print(f\"No valid EIBC data found for {year}!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing {len(data_valid)} countries for EIBC {year}\")\n",
    "    \n",
    "    # Set vmax if not provided (use 95th percentile to avoid outliers)\n",
    "    if vmax is None:\n",
    "        vmax = np.percentile(data_valid[column], 95)\n",
    "    \n",
    "    # Create geometry for plotting\n",
    "    data_valid = data_valid.copy()\n",
    "    data_valid['geometry'] = data_valid.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    geo_df = gpd.GeoDataFrame(data_valid, geometry='geometry')\n",
    "    geo_df.set_crs(epsg=4326, inplace=True)\n",
    "    \n",
    "    # Create figure with Robinson projection\n",
    "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "    \n",
    "    # Set background and map features\n",
    "    ax.set_facecolor(\"#FFFFFF\")  \n",
    "    ax.add_feature(cfeature.LAND, color=\"#CECECE\", alpha=0.4)\n",
    "    ax.add_feature(cfeature.OCEAN, color=\"#FFFFFF\", alpha=0.5)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Set color mapping - using consistent color scheme\n",
    "    sci_colors = ['#012f48', '#669aba', '#fbf0d9', '#be1420', '#7a0101']\n",
    "    custom_cmap = mpl.colors.LinearSegmentedColormap.from_list('sci_palette', sci_colors)\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=vmax)\n",
    "    \n",
    "    # Calculate point sizes\n",
    "    min_size = 25\n",
    "    max_size = 200\n",
    "    \n",
    "    # Sort data to ensure smaller values are plotted first (larger values on top)\n",
    "    geo_df_sorted = geo_df.sort_values(by=column, ascending=True)\n",
    "    \n",
    "    # Create fake scatter for colorbar\n",
    "    fake_scatter = ax.scatter([-1000], [-1000], c=[0], cmap=custom_cmap, \n",
    "                             vmin=0, vmax=vmax, s=1)\n",
    "    \n",
    "    # Plot each point with custom styling\n",
    "    for idx, row in geo_df_sorted.iterrows():\n",
    "        lon, lat = row.geometry.x, row.geometry.y\n",
    "        value = row[column]\n",
    "        \n",
    "        if pd.isna(value) or value <= 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate point size based on value\n",
    "        size_factor = min(value / vmax, 1.0)\n",
    "        size = min_size + (size_factor * (max_size - min_size))\n",
    "        color = custom_cmap(norm(value))\n",
    "        \n",
    "        # Create custom point with border\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi=200)\n",
    "        temp_fig.patch.set_alpha(0)\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # Draw outer circle (border)\n",
    "        outer_circle = plt.Circle((0.5, 0.5), 0.18, color='black', alpha=1)\n",
    "        temp_ax.add_patch(outer_circle)\n",
    "        \n",
    "        # Draw inner circle (data color)\n",
    "        inner_circle = plt.Circle((0.5, 0.5), 0.15, color=color, alpha=1)\n",
    "        temp_ax.add_patch(inner_circle)\n",
    "        \n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')\n",
    "        \n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        point_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # Transform coordinates and add to map\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        zoom_factor = np.sqrt(size) / 80\n",
    "        \n",
    "        imagebox = OffsetImage(point_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0, zorder=10)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(fake_scatter, ax=ax, orientation='horizontal', \n",
    "                       shrink=0.6, pad=0.05, aspect=50)\n",
    "    cbar.set_label(f'EIBC (Energy Investment to GDP Ratio)', fontsize=14)\n",
    "    \n",
    "    # Set title\n",
    "    # ax.set_title(f'Energy Investment Burden Coefficient (EIBC) - {year}', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Set global extent and clean up\n",
    "    ax.set_global()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nEIBC {year} Statistics:\")\n",
    "    print(f\"  Valid countries: {len(data_valid)}\")\n",
    "    print(f\"  Mean EIBC: {data_valid[column].mean():.4f}\")\n",
    "    print(f\"  Median EIBC: {data_valid[column].median():.4f}\")\n",
    "    print(f\"  95th percentile: {np.percentile(data_valid[column], 95):.4f}\")\n",
    "    print(f\"  Max EIBC: {data_valid[column].max():.4f}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Determine consistent vmax for both years\n",
    "eibc_0_valid = df.dropna(subset=['EIBC_0'])['EIBC_0']\n",
    "eibc_2020_valid = df.dropna(subset=['EIBC_2020'])['EIBC_2020']\n",
    "eibc_2050_valid = df.dropna(subset=['EIBC_2050'])['EIBC_2050']\n",
    "\n",
    "if len(eibc_0_valid) > 0 and len(eibc_2020_valid) > 0 and len(eibc_2050_valid) > 0:\n",
    "    # Use 95th percentile of combined data for consistent scaling\n",
    "    combined_eibc = pd.concat([eibc_2020_valid, eibc_2050_valid])\n",
    "    vmax_consistent = np.percentile(combined_eibc, 95)\n",
    "    \n",
    "    print(f\"Using consistent vmax: {vmax_consistent:.4f} for both years\")\n",
    "    \n",
    "    # Create individual visualizations for 2020 and 2050\n",
    "    print(\"\\n=== Creating EIBC 0 Visualization ===\")\n",
    "    fig_0 = visualize_eibc_single(df, '0', 'EIBC_0', vmax=vmax_consistent)\n",
    "    \n",
    "    print(\"\\n=== Creating EIBC 2020 Visualization ===\")\n",
    "    fig_2020 = visualize_eibc_single(df, '2020', 'EIBC_2020', vmax=vmax_consistent)\n",
    "    \n",
    "    print(\"\\n=== Creating EIBC 2050 Visualization ===\")\n",
    "    fig_2050 = visualize_eibc_single(df, '2050', 'EIBC_2050', vmax=vmax_consistent)\n",
    "    \n",
    "else:\n",
    "    print(\"Error: No valid EIBC data found for one or both years!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81739302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot analysis\n",
    "def create_eibc_scatter_plot(data):\n",
    "    \"\"\"Create EIBC scatter plot: 2020 vs 2050 with different shapes and colors\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Filter valid data for both years\n",
    "    data_valid = data.dropna(subset=['EIBC_0', 'EIBC_2020'])\n",
    "    \n",
    "    if len(data_valid) == 0:\n",
    "        print(\"No valid EIBC data found for comparison!\")\n",
    "        return\n",
    "    \n",
    "    # Create figure for scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=300)\n",
    "    \n",
    "    # Convert to percentage for display\n",
    "    eibc_2020_pct = data_valid['EIBC_0'] * 100\n",
    "    eibc_2050_pct = data_valid['EIBC_2020'] * 100\n",
    "    \n",
    "    # Create two different point types based on whether EIBC increased or decreased\n",
    "    increased_mask = eibc_2050_pct > eibc_2020_pct\n",
    "    decreased_mask = eibc_2050_pct <= eibc_2020_pct\n",
    "    \n",
    "    # Scatter plot with different shapes and colors for increases and decreases\n",
    "    if increased_mask.any():\n",
    "        scatter_increase = ax.scatter(eibc_2020_pct[increased_mask], eibc_2050_pct[increased_mask], \n",
    "                                     alpha=0.7, s=60, c='#be1420', marker='^', \n",
    "                                     edgecolors='black', linewidth=0.5, label='EIBC Increased')\n",
    "    \n",
    "    if decreased_mask.any():\n",
    "        scatter_decrease = ax.scatter(eibc_2020_pct[decreased_mask], eibc_2050_pct[decreased_mask], \n",
    "                                     alpha=0.7, s=60, c='#012f48', marker='o', \n",
    "                                     edgecolors='black', linewidth=0.5, label='EIBC Decreased')\n",
    "    \n",
    "    # Add diagonal line for reference (y=x line)\n",
    "    max_val = max(eibc_2020_pct.max(), eibc_2050_pct.max())\n",
    "    ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, linewidth=1, label='y=x (No Change)')\n",
    "    \n",
    "    # Set labels with percentage\n",
    "    ax.set_xlabel('EIBC 0 (%)', fontsize=16)\n",
    "    ax.set_ylabel('EIBC 2020 (%)', fontsize=16)\n",
    "    # ax.set_title('EIBC: 2020 vs 2050', fontsize=16, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=16, edgecolor='black')\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    # Set equal aspect ratio and start from 0\n",
    "    ax.set_xlim(0, max_val * 1.05)\n",
    "    ax.set_ylim(0, max_val * 1.05)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create change analysis with focused view\n",
    "def create_eibc_change_analysis(data):\n",
    "    \"\"\"Create focused EIBC change analysis with percentage values and full bar display\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Filter valid data for both years\n",
    "    data_valid = data.dropna(subset=['EIBC_0', 'EIBC_2020'])\n",
    "    \n",
    "    if len(data_valid) == 0:\n",
    "        print(\"No valid EIBC data found for comparison!\")\n",
    "        return\n",
    "    \n",
    "    # Calculate change and convert to percentage\n",
    "    eibc_change = data_valid['EIBC_2020'] - data_valid['EIBC_0']\n",
    "    eibc_change_pct = eibc_change * 100  # Convert to percentage\n",
    "    \n",
    "    # Create larger figure for change analysis\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=300)\n",
    "    \n",
    "    # Focus on smaller changes - use a much smaller range to emphasize the smaller bars\n",
    "    # Set x-axis limit to focus on very small changes only\n",
    "    change_90th = np.percentile(np.abs(eibc_change_pct), 90)\n",
    "    xlim_max = min(change_90th * 0.3, 0.05)  # Focus on tiny changes in percentage\n",
    "    xlim_min = -xlim_max\n",
    "    \n",
    "    # Filter data for the focused range\n",
    "    focused_changes = eibc_change_pct[(eibc_change_pct >= xlim_min) & (eibc_change_pct <= xlim_max)]\n",
    "    \n",
    "    # Create histogram with focused range and more bins for detail\n",
    "    counts, bins, patches = ax.hist(focused_changes, bins=80, alpha=1, color='#de6a69', edgecolor='black', linewidth=0.3)\n",
    "    ax.axvline(0, color='black', linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax.set_xlabel('EIBC Change (2020 - 0) (%)', fontsize=16)\n",
    "    ax.set_ylabel('Frequency', fontsize=16)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    # ax.set_title('Change in EIBC (2050 - 2020) - Focused on Small Changes (%)', fontsize=16, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set x-axis limits to focus on the very small changes\n",
    "    ax.set_xlim(xlim_min, xlim_max)\n",
    "    \n",
    "    # Show all bars completely - no y-axis cutting\n",
    "    max_count = np.max(counts)\n",
    "    ax.set_ylim(0, max_count * 1.05)  # Add 5% padding at top for better visibility\n",
    "    \n",
    "    # Add text annotation showing the maximum values information (in percentage)\n",
    "    max_positive_change_pct = eibc_change_pct.max()\n",
    "    max_negative_change_pct = eibc_change_pct.min()\n",
    "    max_abs_change_pct = max(abs(max_positive_change_pct), abs(max_negative_change_pct))\n",
    "    \n",
    "    # Create info box with maximum value information\n",
    "    # info_text = f'Maximum Values (Full Dataset):\\n'\n",
    "    info_text = f'Max Increase: {max_positive_change_pct:.4f}%\\n'\n",
    "    info_text += f'Max Decrease: {max_negative_change_pct:.4f}%'\n",
    "    # info_text += f'Max |Change|: {max_abs_change_pct:.4f}%\\n'\n",
    "    # info_text += f'Tallest bar: {max_count} countries\\n'\n",
    "    # info_text += f'(All bars shown completely)'\n",
    "    \n",
    "    ax.text(0.80, 0.95, info_text, transform=ax.transAxes, fontsize=16,\n",
    "           verticalalignment='top', horizontalalignment='left',\n",
    "           bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    # Add inset subplot for positive EIBC changes in the upper left corner\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "    \n",
    "    # Create inset axes in the upper left corner\n",
    "    axins = inset_axes(ax, width=\"35%\", height=\"35%\", loc='upper left', borderpad=4)\n",
    "    \n",
    "    # Filter only positive changes within the focused range\n",
    "    positive_changes = focused_changes[focused_changes > 0]\n",
    "    \n",
    "    if len(positive_changes) > 0:\n",
    "        # Create histogram for positive changes with finer bins\n",
    "        counts_pos, _, _ = axins.hist(positive_changes, bins=30, alpha=1, color='#982b2d', \n",
    "                                     edgecolor='black', linewidth=0.5)\n",
    "        axins.set_xlabel('Positive EIBC Change (%)', fontsize=16)\n",
    "        axins.set_ylabel('Frequency', fontsize=16)\n",
    "        # axins.set_title('EIBC Increases\\n(Zoomed View)', fontsize=16, pad=5)\n",
    "        axins.grid(True, alpha=0.3)\n",
    "        axins.tick_params(labelsize=9)\n",
    "        \n",
    "        # Automatically set y-limit around 80 to focus on smaller bars\n",
    "        max_pos_count = np.max(counts_pos)\n",
    "        \n",
    "        # Find a suitable y-limit around 80 that excludes the tallest bars\n",
    "        # Sort counts to find the distribution\n",
    "        sorted_counts = np.sort(counts_pos[counts_pos > 0])  # Only positive counts\n",
    "        \n",
    "        if len(sorted_counts) > 1:\n",
    "            # Calculate what 80% of the non-zero bars would be\n",
    "            percentile_80_idx = int(len(sorted_counts) * 0.8)\n",
    "            if percentile_80_idx < len(sorted_counts):\n",
    "                suggested_limit = sorted_counts[percentile_80_idx]\n",
    "                \n",
    "                # Ensure the limit is reasonable (between 50 and 120)\n",
    "                target_limit = max(50, min(120, suggested_limit * 1.2))  # 20% padding above 80th percentile\n",
    "                \n",
    "                # If the calculated limit is too close to max, use around 80\n",
    "                if target_limit > max_pos_count * 0.9:\n",
    "                    target_limit = min(80, max_pos_count * 0.7)\n",
    "                    \n",
    "                axins.set_ylim(0, target_limit)\n",
    "            else:\n",
    "                # Fallback: use 80 or 70% of max, whichever is smaller\n",
    "                axins.set_ylim(0, min(80, max_pos_count * 0.7))\n",
    "        else:\n",
    "            # If only one bar, use 80 or the bar height, whichever is smaller\n",
    "            axins.set_ylim(0, min(80, max_pos_count * 1.1))\n",
    "        \n",
    "        # Add statistics text (in percentage)\n",
    "        mean_pos = positive_changes.mean()\n",
    "        median_pos = positive_changes.median()\n",
    "        count_pos = len(positive_changes)\n",
    "        max_pos = positive_changes.max()\n",
    "        \n",
    "        # Get the actual y-limit that was set\n",
    "        actual_ylim = axins.get_ylim()[1]\n",
    "        \n",
    "        # Add text box with statistics including info about y-axis cutting\n",
    "        # stats_text = f'n={count_pos}\\nMean: {mean_pos:.4f}%\\nMedian: {median_pos:.4f}%\\nMax: {max_pos:.4f}%'\n",
    "        # axins.text(0.95, 0.95, stats_text, transform=axins.transAxes, \n",
    "        #           fontsize=8, verticalalignment='top', horizontalalignment='right',\n",
    "        #           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    else:\n",
    "        # If no positive changes in focused range, show a message\n",
    "        axins.text(0.5, 0.5, 'No positive\\nchanges in\\nfocused range', \n",
    "                  transform=axins.transAxes, ha='center', va='center', fontsize=10)\n",
    "        axins.set_xticks([])\n",
    "        axins.set_yticks([])\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed statistics (in percentage)\n",
    "    print(f\"\\n=== EIBC Change Analysis ===\")\n",
    "    print(f\"Total countries with valid data: {len(data_valid)}\")\n",
    "    print(f\"Countries in focused range ({xlim_min:.4f}% to {xlim_max:.4f}%): {len(focused_changes)}\")\n",
    "    \n",
    "    print(f\"\\nOverall Change Statistics:\")\n",
    "    print(f\"  Mean change: {eibc_change_pct.mean():.4f}%\")\n",
    "    print(f\"  Median change: {eibc_change_pct.median():.4f}%\")\n",
    "    print(f\"  Max increase: {max_positive_change_pct:.4f}%\")\n",
    "    print(f\"  Max decrease: {max_negative_change_pct:.4f}%\")\n",
    "    print(f\"  Countries with increased EIBC: {(eibc_change_pct > 0).sum()} ({(eibc_change_pct > 0).mean()*100:.1f}%)\")\n",
    "    print(f\"  Countries with decreased EIBC: {(eibc_change_pct < 0).sum()} ({(eibc_change_pct < 0).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Statistics for focused range\n",
    "    print(f\"\\nFocused Range Statistics:\")\n",
    "    print(f\"  Mean change (focused): {focused_changes.mean():.4f}%\")\n",
    "    print(f\"  Median change (focused): {focused_changes.median():.4f}%\")\n",
    "    print(f\"  Tallest bar height: {max_count} countries\")\n",
    "    print(f\"  All bars displayed completely\")\n",
    "    \n",
    "    # Additional statistics for positive changes in focused range\n",
    "    if len(positive_changes) > 0:\n",
    "        print(f\"\\nPositive Changes in Focused Range:\")\n",
    "        print(f\"  Count: {len(positive_changes)}\")\n",
    "        print(f\"  Mean: {positive_changes.mean():.4f}%\")\n",
    "        print(f\"  Median: {positive_changes.median():.4f}%\")\n",
    "        print(f\"  Max: {positive_changes.max():.4f}%\")\n",
    "        print(f\"  Inset y-limit set to: {axins.get_ylim()[1]:.0f} (to focus on smaller bars)\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"\\n=== Creating EIBC Scatter Plot ===\")\n",
    "fig_scatter = create_eibc_scatter_plot(df)\n",
    "\n",
    "print(\"\\n=== Creating EIBC Change Analysis ===\")\n",
    "fig_change = create_eibc_change_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ca7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot analysis\n",
    "def create_eibc_scatter_plot(data):\n",
    "    \"\"\"Create EIBC scatter plot: 2020 vs 2050 with different shapes and colors\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Filter valid data for both years\n",
    "    data_valid = data.dropna(subset=['EIBC_2020', 'EIBC_2050'])\n",
    "    \n",
    "    if len(data_valid) == 0:\n",
    "        print(\"No valid EIBC data found for comparison!\")\n",
    "        return\n",
    "    \n",
    "    # Create figure for scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=300)\n",
    "    \n",
    "    # Convert to percentage for display\n",
    "    eibc_2020_pct = data_valid['EIBC_2020'] * 100\n",
    "    eibc_2050_pct = data_valid['EIBC_2050'] * 100\n",
    "    \n",
    "    # Create two different point types based on whether EIBC increased or decreased\n",
    "    increased_mask = eibc_2050_pct > eibc_2020_pct\n",
    "    decreased_mask = eibc_2050_pct <= eibc_2020_pct\n",
    "    \n",
    "    # Scatter plot with different shapes and colors for increases and decreases\n",
    "    if increased_mask.any():\n",
    "        scatter_increase = ax.scatter(eibc_2020_pct[increased_mask], eibc_2050_pct[increased_mask], \n",
    "                                     alpha=0.7, s=60, c='#be1420', marker='^', \n",
    "                                     edgecolors='black', linewidth=0.5, label='EIBC Increased')\n",
    "    \n",
    "    if decreased_mask.any():\n",
    "        scatter_decrease = ax.scatter(eibc_2020_pct[decreased_mask], eibc_2050_pct[decreased_mask], \n",
    "                                     alpha=0.7, s=60, c='#012f48', marker='o', \n",
    "                                     edgecolors='black', linewidth=0.5, label='EIBC Decreased')\n",
    "    \n",
    "    # Add diagonal line for reference (y=x line)\n",
    "    max_val = max(eibc_2020_pct.max(), eibc_2050_pct.max())\n",
    "    ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, linewidth=1, label='y=x (No Change)')\n",
    "    \n",
    "    # Set labels with percentage\n",
    "    ax.set_xlabel('EIBC 2020 (%)', fontsize=16)\n",
    "    ax.set_ylabel('EIBC 2050 (%)', fontsize=16)\n",
    "    # ax.set_title('EIBC: 2020 vs 2050', fontsize=16, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=16, edgecolor='black')\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    # Set equal aspect ratio and start from 0\n",
    "    ax.set_xlim(0, max_val * 1.05)\n",
    "    ax.set_ylim(0, max_val * 1.05)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create change analysis with focused view\n",
    "def create_eibc_change_analysis(data):\n",
    "    \"\"\"Create focused EIBC change analysis with percentage values and full bar display\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Filter valid data for both years\n",
    "    data_valid = data.dropna(subset=['EIBC_2020', 'EIBC_2050'])\n",
    "    \n",
    "    if len(data_valid) == 0:\n",
    "        print(\"No valid EIBC data found for comparison!\")\n",
    "        return\n",
    "    \n",
    "    # Calculate change and convert to percentage\n",
    "    eibc_change = data_valid['EIBC_2050'] - data_valid['EIBC_2020']\n",
    "    eibc_change_pct = eibc_change * 100  # Convert to percentage\n",
    "    \n",
    "    # Create larger figure for change analysis\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=300)\n",
    "    \n",
    "    # Focus on smaller changes - use a much smaller range to emphasize the smaller bars\n",
    "    # Set x-axis limit to focus on very small changes only\n",
    "    change_90th = np.percentile(np.abs(eibc_change_pct), 90)\n",
    "    xlim_max = min(change_90th * 0.3, 0.05)  # Focus on tiny changes in percentage\n",
    "    xlim_min = -xlim_max\n",
    "    \n",
    "    # Filter data for the focused range\n",
    "    focused_changes = eibc_change_pct[(eibc_change_pct >= xlim_min) & (eibc_change_pct <= xlim_max)]\n",
    "    \n",
    "    # Create histogram with focused range and more bins for detail\n",
    "    counts, bins, patches = ax.hist(focused_changes, bins=80, alpha=1, color='#de6a69', edgecolor='black', linewidth=0.3)\n",
    "    ax.axvline(0, color='black', linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax.set_xlabel('EIBC Change (2050 - 2020) (%)', fontsize=16)\n",
    "    ax.set_ylabel('Frequency', fontsize=16)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    # ax.set_title('Change in EIBC (2050 - 2020) - Focused on Small Changes (%)', fontsize=16, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set x-axis limits to focus on the very small changes\n",
    "    ax.set_xlim(xlim_min, xlim_max)\n",
    "    \n",
    "    # Show all bars completely - no y-axis cutting\n",
    "    max_count = np.max(counts)\n",
    "    ax.set_ylim(0, max_count * 1.05)  # Add 5% padding at top for better visibility\n",
    "    \n",
    "    # Add text annotation showing the maximum values information (in percentage)\n",
    "    max_positive_change_pct = eibc_change_pct.max()\n",
    "    max_negative_change_pct = eibc_change_pct.min()\n",
    "    max_abs_change_pct = max(abs(max_positive_change_pct), abs(max_negative_change_pct))\n",
    "    \n",
    "    # Create info box with maximum value information\n",
    "    # info_text = f'Maximum Values (Full Dataset):\\n'\n",
    "    info_text = f'Max Increase: {max_positive_change_pct:.4f}%\\n'\n",
    "    info_text += f'Max Decrease: {max_negative_change_pct:.4f}%'\n",
    "    # info_text += f'Max |Change|: {max_abs_change_pct:.4f}%\\n'\n",
    "    # info_text += f'Tallest bar: {max_count} countries\\n'\n",
    "    # info_text += f'(All bars shown completely)'\n",
    "    \n",
    "    ax.text(0.80, 0.95, info_text, transform=ax.transAxes, fontsize=16,\n",
    "           verticalalignment='top', horizontalalignment='left',\n",
    "           bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    # Add inset subplot for positive EIBC changes in the upper left corner\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "    \n",
    "    # Create inset axes in the upper left corner\n",
    "    axins = inset_axes(ax, width=\"35%\", height=\"35%\", loc='upper left', borderpad=4)\n",
    "    \n",
    "    # Filter only positive changes within the focused range\n",
    "    positive_changes = focused_changes[focused_changes > 0]\n",
    "    \n",
    "    if len(positive_changes) > 0:\n",
    "        # Create histogram for positive changes with finer bins\n",
    "        counts_pos, _, _ = axins.hist(positive_changes, bins=30, alpha=1, color='#982b2d', \n",
    "                                     edgecolor='black', linewidth=0.5)\n",
    "        axins.set_xlabel('Positive EIBC Change (%)', fontsize=16)\n",
    "        axins.set_ylabel('Frequency', fontsize=16)\n",
    "        # axins.set_title('EIBC Increases\\n(Zoomed View)', fontsize=16, pad=5)\n",
    "        axins.grid(True, alpha=0.3)\n",
    "        axins.tick_params(labelsize=9)\n",
    "        \n",
    "        # Automatically set y-limit around 80 to focus on smaller bars\n",
    "        max_pos_count = np.max(counts_pos)\n",
    "        \n",
    "        # Find a suitable y-limit around 80 that excludes the tallest bars\n",
    "        # Sort counts to find the distribution\n",
    "        sorted_counts = np.sort(counts_pos[counts_pos > 0])  # Only positive counts\n",
    "        \n",
    "        if len(sorted_counts) > 1:\n",
    "            # Calculate what 80% of the non-zero bars would be\n",
    "            percentile_80_idx = int(len(sorted_counts) * 0.8)\n",
    "            if percentile_80_idx < len(sorted_counts):\n",
    "                suggested_limit = sorted_counts[percentile_80_idx]\n",
    "                \n",
    "                # Ensure the limit is reasonable (between 50 and 120)\n",
    "                target_limit = max(50, min(120, suggested_limit * 1.2))  # 20% padding above 80th percentile\n",
    "                \n",
    "                # If the calculated limit is too close to max, use around 80\n",
    "                if target_limit > max_pos_count * 0.9:\n",
    "                    target_limit = min(80, max_pos_count * 0.7)\n",
    "                    \n",
    "                axins.set_ylim(0, target_limit)\n",
    "            else:\n",
    "                # Fallback: use 80 or 70% of max, whichever is smaller\n",
    "                axins.set_ylim(0, min(80, max_pos_count * 0.7))\n",
    "        else:\n",
    "            # If only one bar, use 80 or the bar height, whichever is smaller\n",
    "            axins.set_ylim(0, min(80, max_pos_count * 1.1))\n",
    "        \n",
    "        # Add statistics text (in percentage)\n",
    "        mean_pos = positive_changes.mean()\n",
    "        median_pos = positive_changes.median()\n",
    "        count_pos = len(positive_changes)\n",
    "        max_pos = positive_changes.max()\n",
    "        \n",
    "        # Get the actual y-limit that was set\n",
    "        actual_ylim = axins.get_ylim()[1]\n",
    "        \n",
    "        # Add text box with statistics including info about y-axis cutting\n",
    "        # stats_text = f'n={count_pos}\\nMean: {mean_pos:.4f}%\\nMedian: {median_pos:.4f}%\\nMax: {max_pos:.4f}%'\n",
    "        # axins.text(0.95, 0.95, stats_text, transform=axins.transAxes, \n",
    "        #           fontsize=8, verticalalignment='top', horizontalalignment='right',\n",
    "        #           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    else:\n",
    "        # If no positive changes in focused range, show a message\n",
    "        axins.text(0.5, 0.5, 'No positive\\nchanges in\\nfocused range', \n",
    "                  transform=axins.transAxes, ha='center', va='center', fontsize=10)\n",
    "        axins.set_xticks([])\n",
    "        axins.set_yticks([])\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed statistics (in percentage)\n",
    "    print(f\"\\n=== EIBC Change Analysis ===\")\n",
    "    print(f\"Total countries with valid data: {len(data_valid)}\")\n",
    "    print(f\"Countries in focused range ({xlim_min:.4f}% to {xlim_max:.4f}%): {len(focused_changes)}\")\n",
    "    \n",
    "    print(f\"\\nOverall Change Statistics:\")\n",
    "    print(f\"  Mean change: {eibc_change_pct.mean():.4f}%\")\n",
    "    print(f\"  Median change: {eibc_change_pct.median():.4f}%\")\n",
    "    print(f\"  Max increase: {max_positive_change_pct:.4f}%\")\n",
    "    print(f\"  Max decrease: {max_negative_change_pct:.4f}%\")\n",
    "    print(f\"  Countries with increased EIBC: {(eibc_change_pct > 0).sum()} ({(eibc_change_pct > 0).mean()*100:.1f}%)\")\n",
    "    print(f\"  Countries with decreased EIBC: {(eibc_change_pct < 0).sum()} ({(eibc_change_pct < 0).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Statistics for focused range\n",
    "    print(f\"\\nFocused Range Statistics:\")\n",
    "    print(f\"  Mean change (focused): {focused_changes.mean():.4f}%\")\n",
    "    print(f\"  Median change (focused): {focused_changes.median():.4f}%\")\n",
    "    print(f\"  Tallest bar height: {max_count} countries\")\n",
    "    print(f\"  All bars displayed completely\")\n",
    "    \n",
    "    # Additional statistics for positive changes in focused range\n",
    "    if len(positive_changes) > 0:\n",
    "        print(f\"\\nPositive Changes in Focused Range:\")\n",
    "        print(f\"  Count: {len(positive_changes)}\")\n",
    "        print(f\"  Mean: {positive_changes.mean():.4f}%\")\n",
    "        print(f\"  Median: {positive_changes.median():.4f}%\")\n",
    "        print(f\"  Max: {positive_changes.max():.4f}%\")\n",
    "        print(f\"  Inset y-limit set to: {axins.get_ylim()[1]:.0f} (to focus on smaller bars)\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"\\n=== Creating EIBC Scatter Plot ===\")\n",
    "fig_scatter = create_eibc_scatter_plot(df)\n",
    "\n",
    "print(\"\\n=== Creating EIBC Change Analysis ===\")\n",
    "fig_change = create_eibc_change_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EIBC difference visualization (2020 - 0)\n",
    "def visualize_eibc_difference(data, vmax=None, vmin=None):\n",
    "    \"\"\"Create EIBC difference visualization (2020 - 0)\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "    import numpy as np\n",
    "    \n",
    "    # Filter data with valid EIBC values for both years\n",
    "    data_valid = data.dropna(subset=['EIBC_0', 'EIBC_2020'])\n",
    "    \n",
    "    if len(data_valid) == 0:\n",
    "        print(\"No valid EIBC data found for difference calculation!\")\n",
    "        return\n",
    "    \n",
    "    # Calculate difference (2050 - 2020)\n",
    "    data_valid = data_valid.copy()\n",
    "    data_valid['EIBC_diff'] = data_valid['EIBC_2020'] - data_valid['EIBC_0']\n",
    "    \n",
    "    print(f\"Processing {len(data_valid)} countries for EIBC difference\")\n",
    "    \n",
    "    # Set vmax and vmin if not provided (use symmetric range around 0)\n",
    "    if vmax is None or vmin is None:\n",
    "        max_abs_diff = max(abs(data_valid['EIBC_diff'].min()), abs(data_valid['EIBC_diff'].max()))\n",
    "        # Use 99th percentile of absolute values to avoid outliers\n",
    "        max_abs_diff = np.percentile(np.abs(data_valid['EIBC_diff']), 99)\n",
    "        vmax = max_abs_diff\n",
    "        vmin = 0\n",
    "    \n",
    "    # Create geometry for plotting\n",
    "    data_valid['geometry'] = data_valid.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    geo_df = gpd.GeoDataFrame(data_valid, geometry='geometry')\n",
    "    geo_df.set_crs(epsg=4326, inplace=True)\n",
    "    \n",
    "    # Create figure with Robinson projection\n",
    "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "\n",
    "    # Set background and map features\n",
    "    ax.set_facecolor(\"#FFFFFF\")  \n",
    "    ax.add_feature(cfeature.LAND, color=\"#CECECE\", alpha=0.4)\n",
    "    ax.add_feature(cfeature.OCEAN, color=\"#FFFFFF\", alpha=0.5)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Set color mapping for difference (blue-white-red)\n",
    "    diff_colors = ['#012f48', '#669aba', '#ffffff', '#be1420', '#7a0101']\n",
    "    diff_cmap = mpl.colors.LinearSegmentedColormap.from_list('diff_palette', diff_colors)\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # Calculate point sizes based on absolute difference\n",
    "    min_size = 25\n",
    "    max_size = 150\n",
    "    \n",
    "    # Sort data to ensure smaller absolute values are plotted first\n",
    "    geo_df_sorted = geo_df.sort_values(by='EIBC_diff', key=abs, ascending=True)\n",
    "    \n",
    "    # Create fake scatter for colorbar\n",
    "    fake_scatter = ax.scatter([-1000], [-1000], c=[0], cmap=diff_cmap, \n",
    "                             vmin=vmin, vmax=vmax, s=1)\n",
    "    \n",
    "    # Plot each point with custom styling\n",
    "    for idx, row in geo_df_sorted.iterrows():\n",
    "        lon, lat = row.geometry.x, row.geometry.y\n",
    "        diff_value = row['EIBC_diff']\n",
    "        \n",
    "        if pd.isna(diff_value):\n",
    "            continue\n",
    "        \n",
    "        # Calculate point size based on absolute difference\n",
    "        abs_diff = abs(diff_value)\n",
    "        size_factor = min(abs_diff / vmax, 1.0)\n",
    "        size = min_size + (size_factor * (max_size - min_size))\n",
    "        color = diff_cmap(norm(diff_value))\n",
    "        \n",
    "        # Create custom point with border\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi=200)\n",
    "        temp_fig.patch.set_alpha(0)\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # Draw outer circle (border)\n",
    "        outer_circle = plt.Circle((0.5, 0.5), 0.18, color='black', alpha=1)\n",
    "        temp_ax.add_patch(outer_circle)\n",
    "        \n",
    "        # Draw inner circle (data color)\n",
    "        inner_circle = plt.Circle((0.5, 0.5), 0.15, color=color, alpha=1)\n",
    "        temp_ax.add_patch(inner_circle)\n",
    "        \n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')\n",
    "        \n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        point_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # Transform coordinates and add to map\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        zoom_factor = np.sqrt(size) / 80\n",
    "        \n",
    "        imagebox = OffsetImage(point_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0, zorder=10)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(fake_scatter, ax=ax, orientation='horizontal', \n",
    "                       shrink=0.6, pad=0.05, aspect=50)\n",
    "    cbar.set_label('EIBC Change (2020 - 0)', fontsize=14)\n",
    "    \n",
    "    # Set title\n",
    "    # ax.set_title('EIBC Change: 2050 - 2020\\n(Blue: Decrease, Red: Increase)', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Set global extent and clean up\n",
    "    ax.set_global()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nEIBC Difference Statistics:\")\n",
    "    print(f\"  Valid countries: {len(data_valid)}\")\n",
    "    print(f\"  Mean change: {data_valid['EIBC_diff'].mean():.4f}\")\n",
    "    print(f\"  Median change: {data_valid['EIBC_diff'].median():.4f}\")\n",
    "    print(f\"  Std change: {data_valid['EIBC_diff'].std():.4f}\")\n",
    "    print(f\"  Min change: {data_valid['EIBC_diff'].min():.4f}\")\n",
    "    print(f\"  Max change: {data_valid['EIBC_diff'].max():.4f}\")\n",
    "    \n",
    "    # Count increases and decreases\n",
    "    increases = (data_valid['EIBC_diff'] > 0).sum()\n",
    "    decreases = (data_valid['EIBC_diff'] < 0).sum()\n",
    "    unchanged = (data_valid['EIBC_diff'] == 0).sum()\n",
    "    \n",
    "    print(f\"  Countries with increased EIBC: {increases} ({increases/len(data_valid)*100:.1f}%)\")\n",
    "    print(f\"  Countries with decreased EIBC: {decreases} ({decreases/len(data_valid)*100:.1f}%)\")\n",
    "    print(f\"  Countries with unchanged EIBC: {unchanged} ({unchanged/len(data_valid)*100:.1f}%)\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create EIBC difference visualization\n",
    "print(\"=== Creating EIBC Difference Visualization ===\")\n",
    "fig_diff = visualize_eibc_difference(df,vmax=0.05,vmin=-0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a29n6gro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EIBC difference visualization (2050 - 2020)\n",
    "def visualize_eibc_difference(data, vmax=None, vmin=None):\n",
    "    \"\"\"Create EIBC difference visualization (2050 - 2020)\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "    import numpy as np\n",
    "    \n",
    "    # Filter data with valid EIBC values for both years\n",
    "    data_valid = data.dropna(subset=['EIBC_2020', 'EIBC_2050'])\n",
    "    \n",
    "    if len(data_valid) == 0:\n",
    "        print(\"No valid EIBC data found for difference calculation!\")\n",
    "        return\n",
    "    \n",
    "    # Calculate difference (2050 - 2020)\n",
    "    data_valid = data_valid.copy()\n",
    "    data_valid['EIBC_diff'] = data_valid['EIBC_2050'] - data_valid['EIBC_2020']\n",
    "    \n",
    "    print(f\"Processing {len(data_valid)} countries for EIBC difference\")\n",
    "    \n",
    "    # Set vmax and vmin if not provided (use symmetric range around 0)\n",
    "    if vmax is None or vmin is None:\n",
    "        max_abs_diff = max(abs(data_valid['EIBC_diff'].min()), abs(data_valid['EIBC_diff'].max()))\n",
    "        # Use 99th percentile of absolute values to avoid outliers\n",
    "        max_abs_diff = np.percentile(np.abs(data_valid['EIBC_diff']), 99)\n",
    "        vmax = max_abs_diff\n",
    "        vmin = -max_abs_diff\n",
    "    \n",
    "    # Create geometry for plotting\n",
    "    data_valid['geometry'] = data_valid.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    geo_df = gpd.GeoDataFrame(data_valid, geometry='geometry')\n",
    "    geo_df.set_crs(epsg=4326, inplace=True)\n",
    "    \n",
    "    # Create figure with Robinson projection\n",
    "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "\n",
    "    # Set background and map features\n",
    "    ax.set_facecolor(\"#FFFFFF\")  \n",
    "    ax.add_feature(cfeature.LAND, color=\"#CECECE\", alpha=0.4)\n",
    "    ax.add_feature(cfeature.OCEAN, color=\"#FFFFFF\", alpha=0.5)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Set color mapping for difference (blue-white-red)\n",
    "    diff_colors = ['#012f48', '#669aba', '#ffffff', '#be1420', '#7a0101']\n",
    "    diff_cmap = mpl.colors.LinearSegmentedColormap.from_list('diff_palette', diff_colors)\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # Calculate point sizes based on absolute difference\n",
    "    min_size = 25\n",
    "    max_size = 150\n",
    "    \n",
    "    # Sort data to ensure smaller absolute values are plotted first\n",
    "    geo_df_sorted = geo_df.sort_values(by='EIBC_diff', key=abs, ascending=True)\n",
    "    \n",
    "    # Create fake scatter for colorbar\n",
    "    fake_scatter = ax.scatter([-1000], [-1000], c=[0], cmap=diff_cmap, \n",
    "                             vmin=vmin, vmax=vmax, s=1)\n",
    "    \n",
    "    # Plot each point with custom styling\n",
    "    for idx, row in geo_df_sorted.iterrows():\n",
    "        lon, lat = row.geometry.x, row.geometry.y\n",
    "        diff_value = row['EIBC_diff']\n",
    "        \n",
    "        if pd.isna(diff_value):\n",
    "            continue\n",
    "        \n",
    "        # Calculate point size based on absolute difference\n",
    "        abs_diff = abs(diff_value)\n",
    "        size_factor = min(abs_diff / vmax, 1.0)\n",
    "        size = min_size + (size_factor * (max_size - min_size))\n",
    "        color = diff_cmap(norm(diff_value))\n",
    "        \n",
    "        # Create custom point with border\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi=200)\n",
    "        temp_fig.patch.set_alpha(0)\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # Draw outer circle (border)\n",
    "        outer_circle = plt.Circle((0.5, 0.5), 0.18, color='black', alpha=1)\n",
    "        temp_ax.add_patch(outer_circle)\n",
    "        \n",
    "        # Draw inner circle (data color)\n",
    "        inner_circle = plt.Circle((0.5, 0.5), 0.15, color=color, alpha=1)\n",
    "        temp_ax.add_patch(inner_circle)\n",
    "        \n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')\n",
    "        \n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        point_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # Transform coordinates and add to map\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        zoom_factor = np.sqrt(size) / 80\n",
    "        \n",
    "        imagebox = OffsetImage(point_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0, zorder=10)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(fake_scatter, ax=ax, orientation='horizontal', \n",
    "                       shrink=0.6, pad=0.05, aspect=50)\n",
    "    cbar.set_label('EIBC Change (2050 - 2020)', fontsize=14)\n",
    "    \n",
    "    # Set title\n",
    "    # ax.set_title('EIBC Change: 2050 - 2020\\n(Blue: Decrease, Red: Increase)', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Set global extent and clean up\n",
    "    ax.set_global()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nEIBC Difference Statistics:\")\n",
    "    print(f\"  Valid countries: {len(data_valid)}\")\n",
    "    print(f\"  Mean change: {data_valid['EIBC_diff'].mean():.4f}\")\n",
    "    print(f\"  Median change: {data_valid['EIBC_diff'].median():.4f}\")\n",
    "    print(f\"  Std change: {data_valid['EIBC_diff'].std():.4f}\")\n",
    "    print(f\"  Min change: {data_valid['EIBC_diff'].min():.4f}\")\n",
    "    print(f\"  Max change: {data_valid['EIBC_diff'].max():.4f}\")\n",
    "    \n",
    "    # Count increases and decreases\n",
    "    increases = (data_valid['EIBC_diff'] > 0).sum()\n",
    "    decreases = (data_valid['EIBC_diff'] < 0).sum()\n",
    "    unchanged = (data_valid['EIBC_diff'] == 0).sum()\n",
    "    \n",
    "    print(f\"  Countries with increased EIBC: {increases} ({increases/len(data_valid)*100:.1f}%)\")\n",
    "    print(f\"  Countries with decreased EIBC: {decreases} ({decreases/len(data_valid)*100:.1f}%)\")\n",
    "    print(f\"  Countries with unchanged EIBC: {unchanged} ({unchanged/len(data_valid)*100:.1f}%)\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create EIBC difference visualization\n",
    "print(\"=== Creating EIBC Difference Visualization ===\")\n",
    "fig_diff = visualize_eibc_difference(df,vmax=0.05,vmin=-0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "island",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
