{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff73fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Set up plotting parameters\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "def load_and_process_data():\n",
    "    \"\"\"Load real data or generate mock data for demonstration\"\"\"\n",
    "    try:\n",
    "        # Try to load real data\n",
    "        demand_data = pd.read_csv(\"../demand_get/data/get1/demand_60.15269_-45.27849.csv\")\n",
    "        system_output = pd.read_csv('../result/output_0/60.15269_-45.27849_results.csv', \n",
    "                                   usecols=['WT', 'PV', 'WEC'])\n",
    "        print(f\"✓ Loaded real data:\")\n",
    "        print(f\"  - Demand data: {len(demand_data)} hours (1-hour resolution)\")\n",
    "        print(f\"  - System output: {len(system_output)} periods (3-hour resolution)\")\n",
    "        \n",
    "        # Get heating demand (try different possible column names)\n",
    "        demand_columns = ['heating_demand', 'Heating_Demand', 'demand', 'Demand']\n",
    "        demand_col = None\n",
    "        for col in demand_columns:\n",
    "            if col in demand_data.columns:\n",
    "                demand_col = col\n",
    "                break\n",
    "        \n",
    "        if demand_col is None and len(demand_data.columns) > 0:\n",
    "            demand_col = demand_data.columns[0]\n",
    "            print(f\"Using first available column as demand: {demand_col}\")\n",
    "        \n",
    "        heating_demand = demand_data[demand_col].values\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"📄 Real data files not found. Generating mock data for demonstration...\")\n",
    "        # Generate one full year of data\n",
    "        # Demand: hourly resolution (8760 hours)\n",
    "        hours_per_year = 8760\n",
    "        periods_per_year = hours_per_year // 3  # 2920 3-hour periods\n",
    "        \n",
    "        # Generate hourly demand data\n",
    "        time_index_hourly = np.arange(hours_per_year)\n",
    "        seasonal_demand = 400 + 300 * np.cos(2 * np.pi * (time_index_hourly - 2160) / hours_per_year)\n",
    "        daily_variation = 100 * np.sin(2 * np.pi * time_index_hourly / 24)\n",
    "        heating_demand = np.maximum(100, seasonal_demand + daily_variation + 50 * np.random.randn(hours_per_year))\n",
    "        \n",
    "        # Generate 3-hourly system output data\n",
    "        time_index_3h = np.arange(periods_per_year)\n",
    "        time_hours_3h = time_index_3h * 3  # Convert to equivalent hours\n",
    "        \n",
    "        # Wind power: higher in winter, variable\n",
    "        wind_seasonal = 200 + 150 * np.cos(2 * np.pi * (time_hours_3h - 1440) / hours_per_year)\n",
    "        wind_variation = 100 * np.random.randn(periods_per_year)\n",
    "        wt_output = np.maximum(0, wind_seasonal + wind_variation)\n",
    "        \n",
    "        # Solar PV: higher in summer, with 3-hour averages\n",
    "        solar_seasonal = 150 * np.maximum(0, np.sin(2 * np.pi * (time_hours_3h - 4380) / hours_per_year))\n",
    "        # Simulate day/night cycle for 3-hour periods\n",
    "        solar_daily = 200 * np.maximum(0, np.sin(2 * np.pi * time_hours_3h / 24))\n",
    "        pv_output = np.maximum(0, solar_seasonal + solar_daily + 30 * np.random.randn(periods_per_year))\n",
    "        \n",
    "        # WEC power: more consistent\n",
    "        wec_base = 120 + 50 * np.cos(2 * np.pi * time_hours_3h / hours_per_year)\n",
    "        wec_output = np.maximum(20, wec_base + 40 * np.random.randn(periods_per_year))\n",
    "        \n",
    "        system_output = pd.DataFrame({\n",
    "            'WT': wt_output,\n",
    "            'PV': pv_output, \n",
    "            'WEC': wec_output\n",
    "        })\n",
    "        \n",
    "        print(f\"✓ Generated mock data:\")\n",
    "        print(f\"  - Demand data: {len(heating_demand)} hours (1-hour resolution)\")\n",
    "        print(f\"  - System output: {len(system_output)} periods (3-hour resolution)\")\n",
    "    \n",
    "    return heating_demand, system_output\n",
    "\n",
    "def resample_demand_to_3hour(hourly_demand):\n",
    "    \"\"\"Resample hourly demand data to 3-hour resolution by taking mean\"\"\"\n",
    "    n_hours = len(hourly_demand)\n",
    "    n_3hours = n_hours // 3\n",
    "    \n",
    "    # Reshape and take mean of every 3 hours\n",
    "    reshaped = hourly_demand[:n_3hours * 3].reshape(-1, 3)\n",
    "    demand_3h = np.mean(reshaped, axis=1)\n",
    "    \n",
    "    print(f\"🔄 Resampled demand from {n_hours} hours to {len(demand_3h)} 3-hour periods\")\n",
    "    return demand_3h\n",
    "\n",
    "def smooth_data(data, window_periods=7*8):\n",
    "    \"\"\"Apply Savitzky-Golay smoothing (window in 3-hour periods)\"\"\"\n",
    "    # For 3-hour data: 7 days = 7*8 = 56 periods\n",
    "    window_3h = max(3, window_periods)\n",
    "    if window_3h % 2 == 0:  # Ensure odd window size\n",
    "        window_3h += 1\n",
    "    \n",
    "    polyorder = min(2, window_3h - 1)\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        smoothed = data.copy()\n",
    "        for col in data.columns:\n",
    "            smoothed[col] = np.maximum(0, savgol_filter(data[col], window_3h, polyorder))\n",
    "        return smoothed\n",
    "    else:\n",
    "        return savgol_filter(data, window_3h, polyorder)\n",
    "\n",
    "def create_monthly_ticks(n_periods):\n",
    "    \"\"\"Create month-based x-axis ticks for 3-hour resolution data\"\"\"\n",
    "    # For 3-hour resolution: 8 periods per day, ~240 periods per month\n",
    "    periods_per_month = [\n",
    "        31*8, 28*8, 31*8, 30*8, 31*8, 30*8,  # Jan-Jun\n",
    "        31*8, 31*8, 30*8, 31*8, 30*8, 31*8   # Jul-Dec\n",
    "    ]\n",
    "    \n",
    "    month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    # Calculate cumulative positions for month boundaries\n",
    "    cumulative_periods = np.cumsum([0] + periods_per_month)\n",
    "    \n",
    "    # Only include months that fit within our data\n",
    "    valid_ticks = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    for i, (pos, label) in enumerate(zip(cumulative_periods, month_labels)):\n",
    "        if pos < n_periods:\n",
    "            valid_ticks.append(pos)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    return valid_ticks, valid_labels\n",
    "\n",
    "def plot_energy_profile(heating_demand, system_output):\n",
    "    \"\"\"Create the main energy supply and demand plot\"\"\"\n",
    "    \n",
    "    # Resample demand from hourly to 3-hour resolution\n",
    "    print(\"🔄 Processing data resolutions...\")\n",
    "    demand_3h = resample_demand_to_3hour(heating_demand)\n",
    "    \n",
    "    # Ensure both datasets have the same length\n",
    "    min_length = min(len(demand_3h), len(system_output))\n",
    "    demand_3h = demand_3h[:min_length]\n",
    "    output_3h = system_output.iloc[:min_length].copy()\n",
    "    \n",
    "    print(f\"✓ Final data length: {min_length} 3-hour periods\")\n",
    "    \n",
    "    # Apply smoothing to both demand and output\n",
    "    print(\"📈 Applying smoothing...\")\n",
    "    smooth_demand = smooth_data(demand_3h)\n",
    "    smooth_output = smooth_data(output_3h)\n",
    "    \n",
    "    # Create stacked data for area plot\n",
    "    stacked_data = pd.DataFrame(index=smooth_output.index)\n",
    "    stacked_data['WEC'] = smooth_output['WEC']  # Bottom layer\n",
    "    stacked_data['WT'] = stacked_data['WEC'] + smooth_output['WT']  # WEC + WT  \n",
    "    stacked_data['PV'] = stacked_data['WT'] + smooth_output['PV']   # WEC + WT + PV\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=300)\n",
    "    \n",
    "    # Define colors\n",
    "    colors = {\n",
    "        'WEC': '#1f77b4',      # Blue for Wave Energy Converter\n",
    "        'WT': '#87ceeb',       # Light blue for Wind Turbine  \n",
    "        'PV': '#ffcc00',       # Gold for Solar PV\n",
    "        'Heating': '#d62728'   # Red for Heating Demand\n",
    "    }\n",
    "    \n",
    "    # Time axis (3-hour periods)\n",
    "    time_axis = np.arange(len(smooth_output))\n",
    "    \n",
    "    # Plot stacked areas\n",
    "    ax.fill_between(time_axis, 0, stacked_data['WEC'], \n",
    "                   color=colors['WEC'], alpha=0.8, label='Wave Energy Converter (WEC)')\n",
    "    ax.fill_between(time_axis, stacked_data['WEC'], stacked_data['WT'],\n",
    "                   color=colors['WT'], alpha=0.8, label='Wind Turbine (WT)')\n",
    "    ax.fill_between(time_axis, stacked_data['WT'], stacked_data['PV'],\n",
    "                   color=colors['PV'], alpha=0.8, label='Solar PV')\n",
    "    \n",
    "    # Add boundary lines for clarity\n",
    "    ax.plot(time_axis, stacked_data['WEC'], color='white', linewidth=0.5, alpha=0.7)\n",
    "    ax.plot(time_axis, stacked_data['WT'], color='white', linewidth=0.5, alpha=0.7)\n",
    "    ax.plot(time_axis, stacked_data['PV'], color='white', linewidth=0.5, alpha=0.7)\n",
    "    \n",
    "    # Plot heating demand line\n",
    "    ax.plot(time_axis, smooth_demand, color=colors['Heating'], \n",
    "           linewidth=3, label='Heating Demand', zorder=5)\n",
    "    \n",
    "    # Set up x-axis with monthly labels\n",
    "    month_ticks, month_labels = create_monthly_ticks(len(time_axis))\n",
    "    ax.set_xticks(month_ticks)\n",
    "    ax.set_xticklabels(month_labels)\n",
    "    \n",
    "    # Labels and formatting\n",
    "    ax.set_xlabel('Month', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Power (kW)', fontsize=16, fontweight='bold')\n",
    "    # ax.set_title('Annual Renewable Energy Supply vs. Heating Demand Profile\\n(3-Hour Resolution)', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "    ax.yaxis.set_tick_params(labelsize=16)\n",
    "    # Set axis limits\n",
    "    y_max = max(stacked_data['PV'].max(), smooth_demand.max()) * 1.1\n",
    "    ax.set_ylim(0, y_max)\n",
    "    ax.set_xlim(0, len(time_axis) - 1)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', fontsize=16, frameon=True, fancybox=True, shadow=False)\n",
    "    \n",
    "    # Grid for better readability\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print some statistics\n",
    "    total_renewable = stacked_data['PV'].iloc[-1] if len(stacked_data) > 0 else 0\n",
    "    avg_demand = smooth_demand.mean() if len(smooth_demand) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 Statistics (3-hour resolution):\")\n",
    "    print(f\"   Average renewable generation: {total_renewable:.1f} kW\")  \n",
    "    print(f\"   Average heating demand: {avg_demand:.1f} kW\")\n",
    "    print(f\"   Data periods: {len(time_axis)} (3-hour periods)\")\n",
    "    if avg_demand > 0:\n",
    "        print(f\"   Renewable coverage: {(total_renewable/avg_demand*100):.1f}%\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Main execution\n",
    "print(\"🚀 Loading and processing energy data...\")\n",
    "heating_demand, system_output = load_and_process_data()\n",
    "\n",
    "print(\"🎨 Creating visualization...\")\n",
    "fig, ax = plot_energy_profile(heating_demand, system_output)\n",
    "\n",
    "print(\"✅ Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd697ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from geopy.distance import great_circle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def load_island_lng_data():\n",
    "    \"\"\"Load island and LNG terminal data\"\"\"\n",
    "    print(\"🏝️ Loading island data...\")\n",
    "    # Read island data\n",
    "    islands = pd.read_csv(\"../visualization/filtered_island_1898.csv\")\n",
    "    # Clean column names and extract coordinates\n",
    "    islands.columns = [col.strip() for col in islands.columns]\n",
    "    if 'Long' in islands.columns and 'Lat' in islands.columns:\n",
    "        islands['lon'] = islands['Long']\n",
    "        islands['lat'] = islands['Lat']\n",
    "    print(f\"✓ Loaded {len(islands)} islands\")\n",
    "    \n",
    "    print(\"⛽ Loading LNG terminal data...\")\n",
    "    # Read LNG terminal data\n",
    "    lng_terminals = pd.read_excel(\"../visualization/LNG_Terminals.xlsx\")\n",
    "    # Filter only operational terminals with valid coordinates\n",
    "    lng_active = lng_terminals[\n",
    "        (lng_terminals['Status'].isin(['Operating', 'Under Construction'])) &\n",
    "        (lng_terminals['Latitude'].notna()) & \n",
    "        (lng_terminals['Longitude'].notna())\n",
    "    ].copy()\n",
    "    lng_active['lon'] = lng_active['Longitude'] \n",
    "    lng_active['lat'] = lng_active['Latitude']\n",
    "    print(f\"✓ Loaded {len(lng_active)} active LNG terminals\")\n",
    "    \n",
    "    return islands, lng_active\n",
    "\n",
    "def calculate_min_distances(islands, lng_terminals):\n",
    "    \"\"\"Calculate minimum great circle distance from each island to nearest LNG terminal\"\"\"\n",
    "    print(\"📏 Calculating distances to nearest LNG terminals...\")\n",
    "    \n",
    "    min_distances = []\n",
    "    \n",
    "    for idx, island in islands.iterrows():\n",
    "        island_coord = (island['lat'], island['lon'])\n",
    "        \n",
    "        # Calculate distance to all LNG terminals\n",
    "        distances = []\n",
    "        for _, terminal in lng_terminals.iterrows():\n",
    "            terminal_coord = (terminal['lat'], terminal['lon'])\n",
    "            # Calculate great circle distance in km and multiply by 1.2\n",
    "            distance = great_circle(island_coord, terminal_coord).kilometers * 1.2\n",
    "            distances.append(distance)\n",
    "        \n",
    "        # Find minimum distance\n",
    "        min_distance = min(distances) if distances else float('inf')\n",
    "        min_distances.append(min_distance)\n",
    "        \n",
    "        if idx % 500 == 0:\n",
    "            print(f\"  Processed {idx}/{len(islands)} islands...\")\n",
    "    \n",
    "    islands['min_lng_distance'] = min_distances\n",
    "    print(f\"✓ Distance calculation complete. Range: {min(min_distances):.1f} - {max(min_distances):.1f} km\")\n",
    "    \n",
    "    return islands\n",
    "\n",
    "def visualize_island_lng_distances(islands, lng_terminals):\n",
    "    \"\"\"Create global map visualization with distance-based color coding\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Create Point geometries for islands\n",
    "    islands['geometry'] = islands.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "    geo_islands = gpd.GeoDataFrame(islands, geometry='geometry')\n",
    "    geo_islands.set_crs(epsg=4326, inplace=True)\n",
    "    \n",
    "    # Create the figure with Robinson projection\n",
    "    fig = plt.figure(figsize=(16, 8), dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "\n",
    "    # Set background and map features\n",
    "    ax.set_facecolor('#FFFFFF')  \n",
    "    ax.add_feature(cfeature.LAND, color=\"#CECECE\", alpha=0.4)\n",
    "    ax.add_feature(cfeature.OCEAN, color=\"#FFFFFF\", alpha=0.5)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Color mapping for islands based on distance to LNG\n",
    "    # Farther from LNG terminals = darker color\n",
    "    sci_colors = ['#012f48', '#669aba', '#fbf0d9', '#be1420', '#7a0101']\n",
    "    custom_cmap = mpl.colors.LinearSegmentedColormap.from_list('sci_palette', sci_colors)\n",
    "    \n",
    "    # Set distance range for color mapping\n",
    "    max_distance = np.percentile(geo_islands['min_lng_distance'], 95)  # Use 95th percentile to avoid outliers\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=max_distance)\n",
    "    \n",
    "    # Point sizes\n",
    "    min_size = 20\n",
    "    max_size = 200\n",
    "    \n",
    "    # Sort islands by distance (closest first, so farthest are on top)\n",
    "    geo_islands = geo_islands.sort_values(by='min_lng_distance')\n",
    "    \n",
    "    print(\"🏝️ Drawing islands...\")\n",
    "    # Draw island points\n",
    "    for idx, row in geo_islands.iterrows():\n",
    "        lon, lat = row.geometry.x, row.geometry.y\n",
    "        distance = row['min_lng_distance']\n",
    "        \n",
    "        # Calculate size and color\n",
    "        size_factor = min(distance / max_distance, 1.0)\n",
    "        size = min_size + (size_factor * (max_size - min_size))\n",
    "        color = custom_cmap(norm(distance))\n",
    "        \n",
    "        # Create point image\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi=100)\n",
    "        temp_fig.patch.set_alpha(0)\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # Draw circle with black border\n",
    "        outer_circle = plt.Circle((0.5, 0.5), 0.18, color='black', alpha=1)\n",
    "        temp_ax.add_patch(outer_circle)\n",
    "        \n",
    "        inner_circle = plt.Circle((0.5, 0.5), 0.15, color=color, alpha=1)\n",
    "        temp_ax.add_patch(inner_circle)\n",
    "        \n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')\n",
    "        \n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        point_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # Transform coordinates and add to map\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        zoom_factor = np.sqrt(size) / 50\n",
    "        \n",
    "        imagebox = OffsetImage(point_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0, zorder=10)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    print(\"⛽ Drawing LNG terminals...\")\n",
    "    # Draw LNG terminals as squares\n",
    "    for _, terminal in lng_terminals.iterrows():\n",
    "        lon, lat = terminal['lon'], terminal['lat']\n",
    "        \n",
    "        # Create square marker for LNG terminals\n",
    "        temp_fig = plt.figure(figsize=(1, 1), frameon=False, dpi=100)\n",
    "        temp_fig.patch.set_alpha(0)\n",
    "        \n",
    "        temp_ax = temp_fig.add_subplot(111)\n",
    "        temp_ax.set_aspect('equal')\n",
    "        temp_ax.patch.set_alpha(0)\n",
    "        \n",
    "        # Draw square\n",
    "        square = plt.Rectangle((0.3, 0.3), 0.4, 0.4, color=\"#D2AB7B\", alpha=1)\n",
    "        temp_ax.add_patch(square)\n",
    "        \n",
    "        temp_ax.set_xlim(0, 1)\n",
    "        temp_ax.set_ylim(0, 1)\n",
    "        temp_ax.axis('off')\n",
    "    \n",
    "        temp_fig.tight_layout(pad=0)\n",
    "        temp_fig.canvas.draw()\n",
    "        terminal_img = np.array(temp_fig.canvas.renderer.buffer_rgba())\n",
    "        plt.close(temp_fig)\n",
    "        \n",
    "        # Transform coordinates and add to map\n",
    "        x, y = ax.projection.transform_point(lon, lat, src_crs=ccrs.PlateCarree())\n",
    "        zoom_factor = 0.12\n",
    "        \n",
    "        imagebox = OffsetImage(terminal_img, zoom=zoom_factor)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0, zorder=5)\n",
    "        ax.add_artist(ab)\n",
    "    \n",
    "    # Create legend for islands and LNG terminals\n",
    "    island_patch = mpatches.Patch(color='#012f48', label='Islands (color by distance to LNG)')\n",
    "    lng_patch = mpatches.Patch(color='#D2AB7B', label='LNG Terminals')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(handles=[island_patch, lng_patch], \n",
    "              loc='lower left', \n",
    "              bbox_to_anchor=(0.02, 0.02), \n",
    "              frameon=True,\n",
    "              fontsize=12,\n",
    "            #   title='Legend',\n",
    "              title_fontsize=12)\n",
    "    \n",
    "    # Create colorbar for island distances\n",
    "    fake_scatter = ax.scatter([-1000], [-1000], c=[0], cmap=custom_cmap, \n",
    "                             vmin=0, vmax=max_distance, s=1)\n",
    "    \n",
    "    cbar = fig.colorbar(fake_scatter, ax=ax, orientation='horizontal', \n",
    "                       shrink=0.6, pad=0.05, aspect=50)\n",
    "    cbar.set_label('Distance to Nearest LNG Terminal (km)', fontsize=14)\n",
    "    \n",
    "    # Add title and finalize\n",
    "    # ax.set_title('Global Islands: Distance to Nearest LNG Terminals\\n(Darker = Farther from LNG)', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "    fig.text(0.42, 0.05, 'Global Islands: Distance to Nearest LNG Terminals\\n(Darker = Farther from LNG)', \n",
    "                    fontsize=9, style='italic', alpha=0.7)\n",
    "    ax.set_global()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n📊 Distance Statistics:\")\n",
    "    print(f\"   Average distance to LNG: {geo_islands['min_lng_distance'].mean():.1f} km\")\n",
    "    print(f\"   Median distance to LNG: {geo_islands['min_lng_distance'].median():.1f} km\")\n",
    "    print(f\"   Islands > 1000 km from LNG: {len(geo_islands[geo_islands['min_lng_distance'] > 1000])}\")\n",
    "    print(f\"   Islands > 5000 km from LNG: {len(geo_islands[geo_islands['min_lng_distance'] > 5000])}\")\n",
    "\n",
    "# Main execution\n",
    "print(\"🚀 Starting global island-LNG distance analysis...\")\n",
    "islands, lng_terminals = load_island_lng_data()\n",
    "islands_with_distances = calculate_min_distances(islands, lng_terminals)\n",
    "visualize_island_lng_distances(islands_with_distances, lng_terminals)\n",
    "print(\"✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i5jhtm1gnwb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# 1. 读取岛屿数据\n",
    "filtered_islands = pd.read_csv('../demand_get/filtered_island_1898.csv')\n",
    "print(f\"读取到 {len(filtered_islands)} 个岛屿\")\n",
    "\n",
    "# 2. 读取IPCC区域数据\n",
    "ipcc_regions = gpd.read_file('../visualization/IPCC-WGI-reference-regions-v4.geojson')\n",
    "print(f\"读取到 {len(ipcc_regions)} 个IPCC区域\")\n",
    "\n",
    "# 3. 将岛屿坐标映射到IPCC区域\n",
    "def map_islands_to_ipcc_regions(islands_df, ipcc_regions):\n",
    "    \"\"\"将岛屿坐标映射到IPCC区域\"\"\"\n",
    "    island_region_mapping = []\n",
    "    \n",
    "    for idx, island in islands_df.iterrows():\n",
    "        lat, lon = island['Lat'], island['Long']\n",
    "        point = Point(lon, lat)  # 注意经纬度的顺序\n",
    "        \n",
    "        # 查找包含该点的IPCC区域\n",
    "        region_found = False\n",
    "        for _, region in ipcc_regions.iterrows():\n",
    "            if region.geometry.contains(point):\n",
    "                island_region_mapping.append({\n",
    "                    'island_lat': lat,\n",
    "                    'island_lon': lon,\n",
    "                    'region_name': region['Name'],\n",
    "                    'region_acronym': region['Acronym'],\n",
    "                    'continent': region['Continent']\n",
    "                })\n",
    "                region_found = True\n",
    "                break\n",
    "        \n",
    "        if not region_found:\n",
    "            island_region_mapping.append({\n",
    "                'island_lat': lat,\n",
    "                'island_lon': lon,\n",
    "                'region_name': 'Unknown',\n",
    "                'region_acronym': 'UNK',\n",
    "                'continent': 'Unknown'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(island_region_mapping)\n",
    "\n",
    "print(\"正在将岛屿映射到IPCC区域...\")\n",
    "island_region_map = map_islands_to_ipcc_regions(filtered_islands, ipcc_regions)\n",
    "\n",
    "# 4. 计算每个区域的岛屿数量\n",
    "region_counts = island_region_map['region_acronym'].value_counts()\n",
    "print(\"\\n各区域岛屿数量：\")\n",
    "print(region_counts.head(15))\n",
    "\n",
    "# 5. 筛选至少有10个岛屿的区域\n",
    "valid_regions = region_counts[region_counts >= 10].index.tolist()\n",
    "print(f\"\\n至少有10个岛屿的区域：{valid_regions}\")\n",
    "\n",
    "# 过滤数据只保留有效区域的岛屿\n",
    "valid_islands = island_region_map[island_region_map['region_acronym'].isin(valid_regions)].copy()\n",
    "print(f\"有效岛屿数量：{len(valid_islands)}\")\n",
    "\n",
    "# 6. 读取每个岛屿的存储容量数据并计算区域平均值\n",
    "def calculate_regional_storage_capacity(valid_islands):\n",
    "    \"\"\"计算每个有效区域的平均存储容量\"\"\"\n",
    "    regional_storage = defaultdict(lambda: {'LNG': [], 'ESS': [], 'TES': [], 'CES': [], 'H2S': []})\n",
    "    \n",
    "    data_path = '../result'\n",
    "    capacity_file = 'island_capacity_0.csv'\n",
    "    capacity_file_path = os.path.join(data_path, capacity_file)\n",
    "    \n",
    "    if os.path.exists(capacity_file_path):\n",
    "        try:\n",
    "            # 读取容量数据\n",
    "            capacity_data = pd.read_csv(capacity_file_path)\n",
    "            print(f\"✓ 读取容量数据: {len(capacity_data)} 条记录\")\n",
    "            \n",
    "            # 假设capacity_data包含lat, lon列用于匹配岛屿\n",
    "            if 'lat' in capacity_data.columns and 'lon' in capacity_data.columns:\n",
    "                # 将容量数据与岛屿-区域映射合并\n",
    "                for _, island in valid_islands.iterrows():\n",
    "                    lat, lon = island['island_lat'], island['island_lon']\n",
    "                    region_acronym = island['region_acronym']\n",
    "                    \n",
    "                    # 查找匹配的容量数据（允许一定误差）\n",
    "                    tolerance = 0.01\n",
    "                    matches = capacity_data[\n",
    "                        (abs(capacity_data['lat'] - lat) < tolerance) & \n",
    "                        (abs(capacity_data['lon'] - lon) < tolerance)\n",
    "                    ]\n",
    "                    \n",
    "                    if len(matches) > 0:\n",
    "                        match = matches.iloc[0]\n",
    "                        # 添加存储容量数据\n",
    "                        storage_types = ['LNG', 'ESS', 'TES', 'CES', 'H2S']\n",
    "                        for storage_type in storage_types:\n",
    "                            if storage_type in match:\n",
    "                                regional_storage[region_acronym][storage_type].append(match[storage_type])\n",
    "                            else:\n",
    "                                regional_storage[region_acronym][storage_type].append(0)\n",
    "            else:\n",
    "                print(\"⚠️ 容量数据中没有lat, lon列，使用随机分布\")\n",
    "                # 使用随机方法分配容量数据到区域\n",
    "                storage_types = ['LNG', 'ESS', 'TES', 'CES', 'H2S']\n",
    "                total_capacity = capacity_data[storage_types].sum() if all(st in capacity_data.columns for st in storage_types) else None\n",
    "                \n",
    "                if total_capacity is not None:\n",
    "                    for _, island in valid_islands.iterrows():\n",
    "                        region_acronym = island['region_acronym']\n",
    "                        for storage_type in storage_types:\n",
    "                            # 随机分配一部分总容量给这个岛屿\n",
    "                            assigned_capacity = total_capacity[storage_type] * np.random.uniform(0.001, 0.01)\n",
    "                            regional_storage[region_acronym][storage_type].append(assigned_capacity)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"读取容量文件时出错: {e}\")\n",
    "            regional_storage = create_mock_storage_data(valid_islands)\n",
    "    else:\n",
    "        print(\"❌ 容量文件不存在，创建模拟数据\")\n",
    "        regional_storage = create_mock_storage_data(valid_islands)\n",
    "    \n",
    "    # 计算每个区域的平均值\n",
    "    region_avg_storage = []\n",
    "    for region, storage_data in regional_storage.items():\n",
    "        if storage_data['LNG']:  # 如果有数据\n",
    "            avg_storage = {}\n",
    "            for storage_type in ['LNG', 'ESS', 'TES', 'CES', 'H2S']:\n",
    "                avg_storage[f'avg_{storage_type.lower()}_capacity'] = np.mean(storage_data[storage_type])\n",
    "            \n",
    "            region_avg_storage.append({\n",
    "                'region_acronym': region,\n",
    "                'avg_lng_capacity': avg_storage['avg_lng_capacity'],\n",
    "                'avg_ess_capacity': avg_storage['avg_ess_capacity'],\n",
    "                'avg_tes_capacity': avg_storage['avg_tes_capacity'],\n",
    "                'avg_ces_capacity': avg_storage['avg_ces_capacity'],\n",
    "                'avg_h2s_capacity': avg_storage['avg_h2s_capacity'],\n",
    "                'island_count': len(storage_data['LNG'])\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(region_avg_storage)\n",
    "\n",
    "def create_mock_storage_data(valid_islands):\n",
    "    \"\"\"创建模拟存储数据\"\"\"\n",
    "    regional_storage = defaultdict(lambda: {'LNG': [], 'ESS': [], 'TES': [], 'CES': [], 'H2S': []})\n",
    "    \n",
    "    for _, island in valid_islands.iterrows():\n",
    "        region_acronym = island['region_acronym']\n",
    "        \n",
    "        # 为每个岛屿生成随机存储容量\n",
    "        lng_cap = np.random.exponential(50)\n",
    "        ess_cap = np.random.exponential(30)\n",
    "        tes_cap = np.random.exponential(20)\n",
    "        ces_cap = np.random.exponential(15)\n",
    "        h2s_cap = np.random.exponential(10)\n",
    "        \n",
    "        regional_storage[region_acronym]['LNG'].append(lng_cap)\n",
    "        regional_storage[region_acronym]['ESS'].append(ess_cap)\n",
    "        regional_storage[region_acronym]['TES'].append(tes_cap)\n",
    "        regional_storage[region_acronym]['CES'].append(ces_cap)\n",
    "        regional_storage[region_acronym]['H2S'].append(h2s_cap)\n",
    "    \n",
    "    return regional_storage\n",
    "\n",
    "# 7. 为每个IPCC区域定义可视化坐标\n",
    "def get_predefined_region_coordinates():\n",
    "    \"\"\"为每个IPCC区域定义固定的可视化坐标位置\"\"\"\n",
    "    region_coords = {\n",
    "        'CAR': (20.0, -60.0),   # Caribbean\n",
    "        'NAO': (40.0, -30.0),   # North Atlantic Ocean\n",
    "        'MED': (35.0, 20.0),    # Mediterranean\n",
    "        'SSA': (-50.0, -70.0),  # Southern South America\n",
    "        'NZ': (-40.0, 175.0),   # New Zealand\n",
    "        'EAS': (30.0, 120.0),   # East Asia\n",
    "        'SPO': (-40.0, -150.0), # South Pacific Ocean\n",
    "        'SEA': (0.0, 125.0),    # Southeast Asia\n",
    "        'NEU': (55.0, 10.0),    # Northern Europe\n",
    "        'GIC': (65.0, -40.0),   # Greenland/Iceland\n",
    "        'AUS': (-25.0, 135.0),  # Australia\n",
    "        'SAO': (-20.0, -10.0),  # South Atlantic Ocean\n",
    "        'SAS': (20.0, 80.0),    # South Asia\n",
    "        'WAS': (15.0, 45.0),    # West Asia\n",
    "        'CAS': (45.0, 70.0),    # Central Asia\n",
    "        'ENA': (45.0, -75.0),   # Eastern North America\n",
    "        'WNA': (45.0, -120.0),  # Western North America\n",
    "        'CNA': (35.0, -100.0),  # Central North America\n",
    "        'NEN': (65.0, 30.0),    # Northern Europe North\n",
    "        'WSA': (-10.0, -60.0),  # Western South America\n",
    "        'NSA': (-5.0, -55.0),   # Northern South America\n",
    "        'NES': (-15.0, -45.0),  # Northeast South America\n",
    "        'SAM': (-30.0, -60.0),  # South America\n",
    "        'WAF': (10.0, 0.0),     # West Africa\n",
    "        'CAF': (0.0, 20.0),     # Central Africa\n",
    "        'EAF': (0.0, 40.0),     # East Africa\n",
    "        'SAF': (-30.0, 25.0),   # Southern Africa\n",
    "        'MDG': (-20.0, 47.0),   # Madagascar\n",
    "        'ESB': (70.0, 120.0),   # East Siberia\n",
    "        'WSB': (65.0, 80.0),    # West Siberia\n",
    "        'RFE': (55.0, 135.0),   # Russian Far East\n",
    "        'RAR': (75.0, 105.0),   # Russian Arctic\n",
    "        'WCA': (40.0, -10.0),   # Western Central Africa\n",
    "        'ECA': (50.0, 20.0),    # Eastern Central Africa\n",
    "        'TIB': (32.0, 90.0),    # Tibet\n",
    "        'EEU': (55.0, 40.0),    # Eastern Europe\n",
    "        'SWS': (-40.0, -73.0),  # Southwest Scandinavia (修正为南美洲西南部)\n",
    "        'NWS': (70.0, 15.0),    # Northwest Scandinavia\n",
    "        'CEU': (50.0, 15.0),    # Central Europe\n",
    "        'WCE': (45.0, 5.0),     # West Central Europe\n",
    "        'ECE': (50.0, 25.0),    # East Central Europe\n",
    "        'MES': (30.0, 50.0),    # Middle East South\n",
    "        'MEN': (35.0, 35.0),    # Middle East North\n",
    "        'ARO': (75.0, 0.0),     # Arctic Ocean\n",
    "        'BOB': (15.0, 90.0),    # Bay of Bengal\n",
    "        'ARS': (15.0, 50.0),    # Arabian Sea\n",
    "        'SCS': (15.0, 115.0),   # South China Sea\n",
    "        'IOD': (-15.0, 75.0),   # Indian Ocean Dipole\n",
    "        'WIO': (-15.0, 60.0),   # Western Indian Ocean\n",
    "        'EIO': (-15.0, 90.0),   # Eastern Indian Ocean\n",
    "        'SIO': (-35.0, 75.0),   # Southern Indian Ocean\n",
    "        'EPO': (-10.0, -120.0), # Eastern Pacific Ocean\n",
    "        'NPO': (30.0, -150.0),  # North Pacific Ocean\n",
    "        'ARP': (15.0, 50.0),    # Arabian Peninsula\n",
    "        'SAH': (25.0, 10.0),    # Sahara\n",
    "        'SCA': (10.0, -85.0),   # Southern Central America\n",
    "        'NWN': (60.0, -140.0),  # Northwest North America\n",
    "        'NAU': (-15.0, 135.0),  # Northern Australia\n",
    "    }\n",
    "    \n",
    "    return region_coords\n",
    "\n",
    "def apply_predefined_coordinates(regional_storage_data):\n",
    "    \"\"\"为有效区域应用预定义的可视化坐标\"\"\"\n",
    "    predefined_coords = get_predefined_region_coordinates()\n",
    "    \n",
    "    region_coords_list = []\n",
    "    for _, region_data in regional_storage_data.iterrows():\n",
    "        region_acronym = region_data['region_acronym']\n",
    "        \n",
    "        if region_acronym in predefined_coords:\n",
    "            lat, lon = predefined_coords[region_acronym]\n",
    "            region_coords_list.append({\n",
    "                'region_acronym': region_acronym,\n",
    "                'center_lat': lat,\n",
    "                'center_lon': lon\n",
    "            })\n",
    "        else:\n",
    "            # 如果没有预定义坐标，使用默认位置\n",
    "            print(f\"警告: 区域 {region_acronym} 没有预定义坐标，使用默认位置\")\n",
    "            region_coords_list.append({\n",
    "                'region_acronym': region_acronym,\n",
    "                'center_lat': 0.0,\n",
    "                'center_lon': 0.0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(region_coords_list)\n",
    "\n",
    "def create_ipcc_regional_storage_pie_chart(final_storage_data):\n",
    "    \"\"\"基于IPCC区域数据创建存储容量饼状图可视化\"\"\"\n",
    "    \n",
    "    # 计算总容量并按总容量排序，确保小饼图先画，不会被大饼图覆盖\n",
    "    final_storage_data['total_capacity'] = (\n",
    "        final_storage_data['avg_lng_capacity'] + \n",
    "        final_storage_data['avg_ess_capacity'] +\n",
    "        final_storage_data['avg_tes_capacity'] + \n",
    "        final_storage_data['avg_ces_capacity'] +\n",
    "        final_storage_data['avg_h2s_capacity']\n",
    "    )\n",
    "    df_sorted = final_storage_data.sort_values(by='total_capacity', ascending=True)\n",
    "    \n",
    "    # 创建带有 cartopy 投影的图形\n",
    "    fig = plt.figure(figsize=(16, 10), dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "    \n",
    "    # 设置背景和地图特征\n",
    "    ax.set_global()\n",
    "    ax.add_feature(cfeature.LAND, facecolor='#E0E0E0', zorder=0)\n",
    "    ax.add_feature(cfeature.OCEAN, facecolor='#FFFFFF', zorder=0)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.7, zorder=1)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, alpha=0.6, zorder=1)\n",
    "    \n",
    "    # 定义饼图的属性\n",
    "    colors = ['#808080', '#1f77b4', '#ff7f0e', '#aec7e8', '#98df8a']\n",
    "    storage_types = ['LNG', 'ESS', 'TES', 'CES', 'H2S']\n",
    "    storage_columns = ['avg_lng_capacity', 'avg_ess_capacity', 'avg_tes_capacity', 'avg_ces_capacity', 'avg_h2s_capacity']\n",
    "    \n",
    "    # 动态调整大小的参数\n",
    "    base_zoom = 0.08  # 饼图的基础缩放比例\n",
    "    scale_factor = 0.00005  # 容量对大小的影响因子\n",
    "    \n",
    "    # 遍历每个区域来绘制饼图\n",
    "    for index, row in df_sorted.iterrows():\n",
    "        lat, lon = row['center_lat'], row['center_lon']\n",
    "        total_capacity = row['total_capacity']\n",
    "        region_name = row['region_acronym']\n",
    "        island_count = row['island_count']\n",
    "        \n",
    "        # 如果总容量为0，则跳过\n",
    "        if total_capacity <= 0:\n",
    "            continue\n",
    "        \n",
    "        # 获取各存储类型的容量\n",
    "        capacities = [row[col] for col in storage_columns]\n",
    "        \n",
    "        # 过滤掉0值，避免空饼块\n",
    "        non_zero_capacities = []\n",
    "        non_zero_colors = []\n",
    "        \n",
    "        for i, cap in enumerate(capacities):\n",
    "            if cap > 0:\n",
    "                non_zero_capacities.append(cap)\n",
    "                non_zero_colors.append(colors[i])\n",
    "        \n",
    "        if not non_zero_capacities:  # 如果没有非零容量\n",
    "            continue\n",
    "            \n",
    "        # 创建一个临时的、透明的画布来生成饼图图像\n",
    "        fig_temp, ax_temp = plt.subplots(figsize=(2, 2), dpi=150)\n",
    "        fig_temp.patch.set_alpha(0)  # 图窗背景透明\n",
    "        ax_temp.patch.set_alpha(0)   # 坐标轴背景透明\n",
    "        \n",
    "        # 在临时坐标轴上绘制饼图\n",
    "        wedges, texts = ax_temp.pie(\n",
    "            non_zero_capacities,\n",
    "            colors=non_zero_colors,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},\n",
    "            startangle=90\n",
    "        )\n",
    "        ax_temp.set_aspect('equal')  # 保证是圆形\n",
    "        ax_temp.axis('off')  # 关闭坐标轴显示\n",
    "        fig_temp.tight_layout(pad=0)  # 去除白边\n",
    "        \n",
    "        # 将绘制好的饼图渲染成一个Numpy数组图像\n",
    "        fig_temp.canvas.draw()\n",
    "        pie_img = np.array(fig_temp.canvas.renderer.buffer_rgba())\n",
    "        plt.close(fig_temp)  # 关闭临时图像，释放内存\n",
    "        \n",
    "        # 计算饼图的动态大小 (缩放比例)\n",
    "        zoom = base_zoom + scale_factor * total_capacity\n",
    "        zoom = max(0.05, min(zoom, 0.25))  # 限制缩放范围\n",
    "        \n",
    "        # 将饼图图像作为OffsetImage添加到主地图上\n",
    "        # 将地理坐标转换为地图投影坐标\n",
    "        point_in_map_proj = ax.projection.transform_point(lon, lat, ccrs.Geodetic())\n",
    "        \n",
    "        # 创建图像盒子\n",
    "        imagebox = OffsetImage(pie_img, zoom=zoom)\n",
    "        imagebox.image.axes = ax\n",
    "        \n",
    "        # 使用AnnotationBbox将图像盒子精确放置在地图上\n",
    "        ab = AnnotationBbox(\n",
    "            imagebox,\n",
    "            point_in_map_proj,\n",
    "            frameon=False,\n",
    "            pad=0\n",
    "        )\n",
    "        ax.add_artist(ab)\n",
    "        \n",
    "        # 在饼图旁边标注区域名称\n",
    "        label_text = f\"{region_name}\"\n",
    "        \n",
    "        # 根据位置调整标签位置\n",
    "        offset_lon = 5 if lon < 0 else -5\n",
    "        offset_lat = -5 if lat > 0 else 5\n",
    "        \n",
    "        ax.text(lon + offset_lon,\n",
    "                lat + offset_lat,\n",
    "                label_text,\n",
    "                transform=ccrs.Geodetic(),\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                zorder=11,\n",
    "                fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\",\n",
    "                          facecolor=\"white\", \n",
    "                          edgecolor=\"gray\",\n",
    "                          alpha=0.8))\n",
    "    \n",
    "    # 创建图例\n",
    "    legend_patches = []\n",
    "    for i, storage_type in enumerate(storage_types):\n",
    "        legend_patches.append(mpatches.Patch(color=colors[i], label=storage_type))\n",
    "    \n",
    "    ax.legend(handles=legend_patches, \n",
    "              loc='lower left', \n",
    "              bbox_to_anchor=(0.02, 0.02), \n",
    "              frameon=True,\n",
    "              fontsize=12)\n",
    "    \n",
    "    # 添加标题\n",
    "    # ax.set_title('Global Island Storage Capacity Distribution by IPCC Regions', \n",
    "    #             fontsize=14, pad=15)\n",
    "    \n",
    "    # 移除边框\n",
    "    plt.setp(ax.spines.values(), visible=False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 执行存储容量数据处理和可视化\n",
    "print(\"\\n正在计算各区域的平均存储容量...\")\n",
    "regional_storage_data = calculate_regional_storage_capacity(valid_islands)\n",
    "\n",
    "if len(regional_storage_data) > 0:\n",
    "    print(\"\\n各区域平均存储容量数据：\")\n",
    "    print(regional_storage_data)\n",
    "    \n",
    "    # 应用预定义坐标\n",
    "    storage_coordinates = apply_predefined_coordinates(regional_storage_data)\n",
    "    \n",
    "    # 合并数据用于可视化\n",
    "    final_storage_data = regional_storage_data.merge(storage_coordinates, on='region_acronym')\n",
    "    \n",
    "    print(\"\\n最终存储数据（包含预定义坐标）：\")\n",
    "    print(final_storage_data[['region_acronym', 'avg_lng_capacity', 'avg_ess_capacity', \n",
    "                             'avg_tes_capacity', 'avg_ces_capacity', 'avg_h2s_capacity', 'island_count']])\n",
    "    \n",
    "    # 创建存储容量可视化图表\n",
    "    print(\"\\n正在创建IPCC区域平均存储容量饼状图...\")\n",
    "    fig_storage = create_ipcc_regional_storage_pie_chart(final_storage_data)\n",
    "    print(\"\\n存储容量可视化完成！\")\n",
    "    \n",
    "    # 显示统计信息\n",
    "    print(\"\\n=== 存储容量统计信息 ===\")\n",
    "    print(f\"有效IPCC区域数量: {len(final_storage_data)}\")\n",
    "    print(f\"包含的岛屿总数: {final_storage_data['island_count'].sum()}\")\n",
    "    print(f\"平均每区域岛屿数: {final_storage_data['island_count'].mean():.1f}\")\n",
    "    \n",
    "    # 计算各存储类型的总容量\n",
    "    total_lng = final_storage_data['avg_lng_capacity'].sum()\n",
    "    total_ess = final_storage_data['avg_ess_capacity'].sum()\n",
    "    total_tes = final_storage_data['avg_tes_capacity'].sum()\n",
    "    total_ces = final_storage_data['avg_ces_capacity'].sum()\n",
    "    total_h2s = final_storage_data['avg_h2s_capacity'].sum()\n",
    "    grand_total = total_lng + total_ess + total_tes + total_ces + total_h2s\n",
    "    \n",
    "    print(f\"\\n各存储类型总容量:\")\n",
    "    print(f\"LNG: {total_lng:.1f} ({total_lng/grand_total*100:.1f}%)\")\n",
    "    print(f\"ESS: {total_ess:.1f} ({total_ess/grand_total*100:.1f}%)\")\n",
    "    print(f\"TES: {total_tes:.1f} ({total_tes/grand_total*100:.1f}%)\")\n",
    "    print(f\"CES: {total_ces:.1f} ({total_ces/grand_total*100:.1f}%)\")\n",
    "    print(f\"H2S: {total_h2s:.1f} ({total_h2s/grand_total*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"没有找到符合条件的区域存储容量数据！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "island",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
