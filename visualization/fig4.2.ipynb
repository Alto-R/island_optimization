{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib.lines import Line2D # Required for creating custom legend elements\n",
    "# Core ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "class AdvancedEnergyAnalysis:\n",
    "    \"\"\"\n",
    "    Advanced analysis class implementing a streamlined four-stage progressive modeling approach.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.results = {}\n",
    "        self.models = {}\n",
    "        self.data = None\n",
    "        self.feature_names = None\n",
    "        self.target_names = None\n",
    "        \n",
    "        # Equipment repair times in hours\n",
    "        self.repair_time_hours = {\n",
    "            'WT': 336,   # Wind Turbine: 336 hours\n",
    "            'PV': 96,    # PV: 96 hours  \n",
    "            'WEC': 336,  # WEC: 336 hours\n",
    "            'LNG': 96    # LNG/CHP: 96 hours\n",
    "        }\n",
    "        \n",
    "        # Convert to 3-hour time steps for simulation\n",
    "        self.repair_time_steps = {\n",
    "            device: hours // 3 for device, hours in self.repair_time_hours.items()\n",
    "        }\n",
    "        \n",
    "        # Set Nature journal plotting style\n",
    "        plt.style.use('default')\n",
    "        plt.rcParams.update({\n",
    "            'font.family': 'Arial',\n",
    "            'font.size': 10,\n",
    "            'axes.labelsize': 10,\n",
    "            'axes.titlesize': 11,\n",
    "            'xtick.labelsize': 9,\n",
    "            'ytick.labelsize': 9,\n",
    "            'legend.fontsize': 9,\n",
    "            'figure.dpi': 300,\n",
    "            'savefig.dpi': 300,\n",
    "            'axes.linewidth': 0.8,\n",
    "            'grid.linewidth': 0.4,\n",
    "            'axes.spines.top': False,\n",
    "            'axes.spines.right': False,\n",
    "            'xtick.direction': 'out',\n",
    "            'ytick.direction': 'out',\n",
    "            'axes.edgecolor': '#333333',\n",
    "            'text.color': '#333333',\n",
    "            'axes.labelcolor': '#333333',\n",
    "            'xtick.color': '#333333',\n",
    "            'ytick.color': '#333333'\n",
    "        })\n",
    "    \n",
    "    def failure_probability_wt(self, ve):\n",
    "        \"\"\"Wind Turbine failure probability based on wind speed\"\"\"\n",
    "        if ve < 30:\n",
    "            return 0\n",
    "        elif ve >= 60:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return (ve - 30) / (60 - 30)\n",
    "    \n",
    "    def failure_probability_pv(self, ve):\n",
    "        \"\"\"PV failure probability based on wind speed\"\"\"\n",
    "        if ve < 40:\n",
    "            return 0\n",
    "        elif ve >= 80:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return (ve - 40) / (80 - 40)\n",
    "    \n",
    "    def failure_probability_wec(self, ve):\n",
    "        \"\"\"WEC failure probability based on wind speed (simplified)\"\"\"\n",
    "        if ve < 35:\n",
    "            return 0\n",
    "        elif ve >= 70:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return (ve - 35) / (70 - 35)\n",
    "    \n",
    "    def device_state_simulation(self, wind_speeds):\n",
    "        \"\"\"\n",
    "        Simulate device states over time considering failure and repair dynamics.\n",
    "        \"\"\"\n",
    "        time_horizon = len(wind_speeds)\n",
    "        device_generate = ['WT', 'PV', 'WEC', 'LNG']\n",
    "        device_states_df = pd.DataFrame(index=range(time_horizon), columns=device_generate, dtype=int)\n",
    "        \n",
    "        device_states = {device: 1 for device in device_generate}  # 1 = working, 0 = failed\n",
    "        time_in_states = {device: 0 for device in device_generate}\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        for t in range(time_horizon):\n",
    "            V = wind_speeds.iloc[t] if hasattr(wind_speeds, 'iloc') else wind_speeds[t]\n",
    "            \n",
    "            for device in device_generate:\n",
    "                if device == 'LNG':\n",
    "                    # LNG fails when wind speed > 20 m/s\n",
    "                    if V > 20:\n",
    "                        device_states[device] = 0\n",
    "                        time_in_states[device] = 0\n",
    "                    else:\n",
    "                        device_states[device] = 1\n",
    "                else:\n",
    "                    # Check for new failures in working equipment\n",
    "                    if device_states[device] == 1:\n",
    "                        if device == 'WT':\n",
    "                            failure_prob = self.failure_probability_wt(V)\n",
    "                        elif device == 'PV':\n",
    "                            failure_prob = self.failure_probability_pv(V)\n",
    "                        elif device == 'WEC':\n",
    "                            failure_prob = self.failure_probability_wec(V)\n",
    "                        else:\n",
    "                            failure_prob = 0\n",
    "                        \n",
    "                        if np.random.random() < failure_prob:\n",
    "                            device_states[device] = 0\n",
    "                            time_in_states[device] = 0\n",
    "                \n",
    "                    # Handle repair for failed equipment\n",
    "                    if device_states[device] == 0:\n",
    "                        # Repair is only possible when wind speed is suitable (‚â§ 20 m/s)\n",
    "                        if V <= 20:\n",
    "                            time_in_states[device] += 1\n",
    "                        \n",
    "                        # Check if repair is complete\n",
    "                        if time_in_states[device] >= self.repair_time_steps[device]:\n",
    "                            device_states[device] = 1\n",
    "                            time_in_states[device] = 0\n",
    "                \n",
    "                # High wind speed forces all equipment to stop\n",
    "                if V > 20:\n",
    "                    device_states[device] = 0\n",
    "                \n",
    "                device_states_df.at[t, device] = device_states[device]\n",
    "        \n",
    "        return device_states_df\n",
    "    \n",
    "    def extract_failure_features(self, scenario_df):\n",
    "        \"\"\"\n",
    "        Extract comprehensive failure features from equipment failure simulation.\n",
    "        Returns all durations in hours.\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        devices = scenario_df.columns\n",
    "        time_step_hours = 3\n",
    "        \n",
    "        for device in devices:\n",
    "            downtime = 1 - scenario_df[device]\n",
    "            total_downtime_steps = downtime.sum()\n",
    "            features[f'total_downtime_hours_{device}'] = total_downtime_steps * time_step_hours\n",
    "            \n",
    "            consecutive_groups = (downtime != downtime.shift()).cumsum()\n",
    "            consecutive_downtime = downtime.groupby(consecutive_groups).sum()\n",
    "            max_consecutive_steps = consecutive_downtime.max() if not consecutive_downtime.empty else 0\n",
    "            features[f'max_consecutive_downtime_hours_{device}'] = max_consecutive_steps * time_step_hours\n",
    "\n",
    "        # Use the maximum consecutive downtime across all devices as a key system reliability feature\n",
    "        max_system_downtime_hours = max(features.get(f'max_consecutive_downtime_hours_{d}', 0) for d in devices)\n",
    "        features['max_failure_duration_hours'] = max_system_downtime_hours\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def calculate_real_data(self):\n",
    "        \"\"\"\n",
    "        Calculate comprehensive island energy system data for both 2020 and 2050 scenarios.\n",
    "        \"\"\"\n",
    "        print(\"Loading and preparing island energy system data for 2020 and 2050 scenarios...\")\n",
    "        \n",
    "        islands_df = pd.read_csv('../result/island_data_origin.csv')\n",
    "        results_data = []\n",
    "        \n",
    "        scenarios = {\n",
    "            2020: {'output_dir': '../result/output_2020', 'cost_summary_file': '../result/island_cost_summary_2020.csv'},\n",
    "            2050: {'output_dir': '../result/output_2050', 'cost_summary_file': '../result/island_cost_summary_2050.csv'}\n",
    "        }\n",
    "        \n",
    "        windspeed_dir = '../result/island_windspeed_data'\n",
    "        demand_dir = '../demand_get/data/get1'\n",
    "        \n",
    "        for year, config in scenarios.items():\n",
    "            print(f\"Processing {year} scenario...\")\n",
    "            cost_summary_df = pd.read_csv(config['cost_summary_file'])\n",
    "            \n",
    "            for _, island in islands_df.iterrows():\n",
    "                lat, lon = island['Lat'], island['Long']\n",
    "                \n",
    "                windspeed_file = os.path.join(windspeed_dir, f\"{lat}_{lon}_{year}_windspeed.csv\")\n",
    "                output_file = os.path.join(config['output_dir'], f\"{lat}_{lon}_results.csv\")\n",
    "                demand_file = os.path.join(demand_dir, f\"demand_{lat}_{lon}.csv\")\n",
    "                \n",
    "                cost_data = cost_summary_df[(cost_summary_df['lat'] == lat) & (cost_summary_df['lon'] == lon)]\n",
    "\n",
    "                if os.path.exists(windspeed_file) and os.path.exists(output_file) and not cost_data.empty:\n",
    "                    try:\n",
    "                        wind_df = pd.read_csv(windspeed_file)\n",
    "                        wind_col = f'Wind_Speed_{year}' if f'Wind_Speed_{year}' in wind_df.columns else wind_df.columns[0]\n",
    "                        wind_speeds = wind_df[wind_col]\n",
    "                        pdi = (wind_speeds ** 3).sum()\n",
    "                        \n",
    "                        device_states_df = self.device_state_simulation(wind_speeds)\n",
    "                        failure_features = self.extract_failure_features(device_states_df)\n",
    "                        max_failure_duration = failure_features['max_failure_duration_hours']\n",
    "                        \n",
    "                        output_df = pd.read_csv(output_file)\n",
    "                        e_wt = output_df.get('WT', pd.Series(0)).sum()\n",
    "                        e_pv = output_df.get('PV', pd.Series(0)).sum()\n",
    "                        e_wec = output_df.get('WEC', pd.Series(0)).sum()\n",
    "                        e_chp = output_df.get('CHP_electric_output', pd.Series(0)).sum()\n",
    "                        \n",
    "                        renewable_energy = e_wt + e_pv + e_wec\n",
    "                        total_energy = renewable_energy + e_chp\n",
    "                        renewable_penetration = renewable_energy / total_energy if total_energy > 0 else 0\n",
    "                        \n",
    "                        cost_data_row = cost_data.iloc[0]\n",
    "                        \n",
    "                        results_data.append({\n",
    "                            'ID': island['ID'], 'Long': lon, 'Lat': lat, 'Country': island['Country'],\n",
    "                            'Island': island['Island'], 'Population': island['pop'], 'Year': year,\n",
    "                            'PDI': pdi,\n",
    "                            'Max_Failure_Duration_Hours': max_failure_duration,\n",
    "                            'Renewable_Penetration': renewable_penetration,\n",
    "                            'Renewable_Cost': cost_data_row.get('renewable_cost_per_capita', 0),\n",
    "                            'Total_Storage_Investment': cost_data_row.get('storage_cost_per_capita', 0),\n",
    "                            'LNG_Cost': cost_data_row.get('lng_cost_per_capita', 0)\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        # print(f\"Skipping island {lat},{lon} for {year} due to error: {e}\")\n",
    "                        continue\n",
    "        \n",
    "        analysis_df = pd.DataFrame(results_data)\n",
    "        if analysis_df.empty:\n",
    "            print(\"‚ùå Error: No data available for analysis\")\n",
    "            return None\n",
    "        \n",
    "        self.data = analysis_df.dropna()\n",
    "        print(f\"Data loaded successfully: {len(self.data)} records\")\n",
    "        \n",
    "        self.feature_names = ['PDI', 'Max_Failure_Duration_Hours']\n",
    "        self.target_names = ['Renewable_Cost', 'Total_Storage_Investment', 'LNG_Cost']\n",
    "        \n",
    "        return self.data\n",
    "\n",
    "    def apply_data_cleaning(self, strategy='moderate'):\n",
    "        \"\"\"\n",
    "        Apply data cleaning strategy.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"‚ùå Error: No data loaded\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\nüîß Applying {strategy.upper()} data cleaning strategy...\")\n",
    "        df_cleaned = self.data.copy()\n",
    "        original_count = len(df_cleaned)\n",
    "        \n",
    "        # Remove cases where all investment costs are zero, as they represent unoptimized scenarios\n",
    "        mask_all_zero = (\n",
    "            (df_cleaned['Renewable_Cost'] == 0) & \n",
    "            (df_cleaned['Total_Storage_Investment'] == 0) & \n",
    "            (df_cleaned['LNG_Cost'] == 0)\n",
    "        )\n",
    "        df_cleaned = df_cleaned[~mask_all_zero]\n",
    "        \n",
    "        final_count = len(df_cleaned)\n",
    "        removed_count = original_count - final_count\n",
    "        print(f\"  ‚Ä¢ Original records: {original_count}\")\n",
    "        print(f\"  ‚Ä¢ Final records: {final_count} (Removed: {removed_count}, {removed_count/original_count:.1%})\")\n",
    "        \n",
    "        self.data = df_cleaned\n",
    "        return df_cleaned\n",
    "\n",
    "    def stage1_correlation_analysis(self):\n",
    "        \"\"\"\n",
    "        Stage 1: Correlation Analysis - Global view with heatmap and collinearity checks.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üéØ STAGE 1: CORRELATION ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_vars = self.feature_names + self.target_names\n",
    "        corr_matrix = self.data[all_vars].corr()\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, fmt='.3f')\n",
    "        plt.title('Full Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nüìä Correlation Analysis Results:\")\n",
    "        # VIF Analysis for collinearity\n",
    "        X = self.data[self.feature_names].values\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"Feature\"] = self.feature_names\n",
    "        vif_data[\"VIF\"] = [variance_inflation_factor(X, i) for i in range(len(self.feature_names))]\n",
    "        \n",
    "        print(\"  VIF Values (>5 suggests potential multicollinearity):\")\n",
    "        for _, row in vif_data.iterrows():\n",
    "            status = \"‚ö†Ô∏è\" if row[\"VIF\"] > 5 else \"‚úÖ\"\n",
    "            print(f\"    {status} {row['Feature']}: {row['VIF']:.2f}\")\n",
    "            \n",
    "        self.results['stage1'] = {'correlation_matrix': corr_matrix, 'vif': vif_data}\n",
    "\n",
    "    def stage2_linear_modeling(self):\n",
    "        \"\"\"\n",
    "        Stage 2: Linear Modeling and Performance Evaluation.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìè STAGE 2: LINEAR MODELING\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        linear_results = {}\n",
    "        X = self.data[self.feature_names]\n",
    "        \n",
    "        for target in self.target_names:\n",
    "            print(f\"\\nüìä Analyzing {target.replace('_', ' ')}:\")\n",
    "            y = self.data[target]\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=self.random_state)\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            y_pred_test = model.predict(X_test_scaled)\n",
    "            test_r2 = r2_score(y_test, y_pred_test)\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "            \n",
    "            X_scaled_full = scaler.transform(X)\n",
    "            cv_scores = cross_val_score(model, X_scaled_full, y, cv=5, scoring='r2')\n",
    "            \n",
    "            print(f\"  ‚Ä¢ Test R¬≤: {test_r2:.4f}\")\n",
    "            print(f\"  ‚Ä¢ Test RMSE: {test_rmse:.2f}\")\n",
    "            print(f\"  ‚Ä¢ CV R¬≤ (mean¬±std): {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "            \n",
    "            feature_importance = np.abs(model.coef_) / np.sum(np.abs(model.coef_))\n",
    "            \n",
    "            linear_results[target] = {\n",
    "                'model': model, 'scaler': scaler, 'test_r2': test_r2,\n",
    "                'y_test': y_test, 'y_pred_test': y_pred_test,\n",
    "                'coefficients': model.coef_, 'feature_importance': feature_importance\n",
    "            }\n",
    "        \n",
    "        self.models['linear'] = linear_results\n",
    "        self.results['stage2'] = linear_results\n",
    "        self.visualize_linear_results()\n",
    "        \n",
    "    def visualize_linear_results(self):\n",
    "        \"\"\"\n",
    "        Visualize linear regression results including feature importance and prediction accuracy.\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, len(self.target_names), figsize=(18, 10))\n",
    "        fig.suptitle('Stage 2: Linear Regression Analysis Results', fontsize=18, fontweight='bold')\n",
    "        colors = ['#2E8B57', '#4169E1', '#DC143C']\n",
    "        \n",
    "        for i, target in enumerate(self.target_names):\n",
    "            results = self.results['stage2'][target]\n",
    "            \n",
    "            # Feature Importance\n",
    "            ax1 = axes[0, i]\n",
    "            importance_df = pd.DataFrame({\n",
    "                'Feature': self.feature_names,\n",
    "                'Importance': results['feature_importance']\n",
    "            }).sort_values('Importance', ascending=True)\n",
    "            ax1.barh(importance_df['Feature'], importance_df['Importance'], color=colors[i], alpha=0.7)\n",
    "            ax1.set_xlabel('Normalized Importance')\n",
    "            ax1.set_title(f'{target.replace(\"_\", \" \")}\\nFeature Importance')\n",
    "            \n",
    "            # Predicted vs Actual\n",
    "            ax2 = axes[1, i]\n",
    "            ax2.scatter(results['y_test'], results['y_pred_test'], alpha=0.7, color=colors[i], edgecolors='w')\n",
    "            min_val = min(results['y_test'].min(), results['y_pred_test'].min())\n",
    "            max_val = max(results['y_test'].max(), results['y_pred_test'].max())\n",
    "            ax2.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)\n",
    "            ax2.set_xlabel('Actual Values')\n",
    "            ax2.set_ylabel('Predicted Values')\n",
    "            ax2.set_title(f'R¬≤ = {results[\"test_r2\"]:.3f}')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "\n",
    "    def stage3_deep_interpretation(self):\n",
    "        \"\"\"\n",
    "        Stage 3: Linear Model Interpretation - Coefficient analysis.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üî¨ STAGE 3: LINEAR MODEL INTERPRETATION\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for target in self.target_names:\n",
    "            print(f\"\\nüéØ Linear model interpretation for {target.replace('_', ' ')}:\")\n",
    "            results = self.results['stage2'][target]\n",
    "            model = results['model']\n",
    "            \n",
    "            coef_df = pd.DataFrame({\n",
    "                'Feature': self.feature_names,\n",
    "                'Coefficient': model.coef_\n",
    "            }).sort_values('Coefficient', ascending=False)\n",
    "            \n",
    "            print(\"  üìà Standardized Coefficients:\")\n",
    "            for _, row in coef_df.iterrows():\n",
    "                print(f\"    {row['Feature']:<30}: {row['Coefficient']:.4f}\")\n",
    "        \n",
    "            self.visualize_coefficients(coef_df, target)\n",
    "\n",
    "    def visualize_coefficients(self, coef_df, target):\n",
    "        \"\"\"Visualize coefficients for a single target model.\"\"\"\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        colors = ['red' if x < 0 else 'blue' for x in coef_df['Coefficient']]\n",
    "        plt.barh(coef_df['Feature'], coef_df['Coefficient'], color=colors, alpha=0.7)\n",
    "        plt.xlabel('Standardized Coefficient Value')\n",
    "        plt.title(f'Coefficient Analysis for {target.replace(\"_\", \" \")}')\n",
    "        plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def stage4_advanced_correlation_analysis(self):\n",
    "        \"\"\"\n",
    "        Stage 4: Advanced Correlation Analysis using a sliding window to\n",
    "        investigate how disaster-cost relationships change with renewable penetration.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üß™ STAGE 4: ADVANCED CORRELATION ANALYSIS (SLIDING WINDOW)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        self.plot_multi_target_correlation_trends()\n",
    "\n",
    "\n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"\n",
    "        Generate a comprehensive analysis report summarizing all stages.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìã COMPREHENSIVE ANALYSIS REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(\"\\nüéØ SUMMARY OF FINDINGS:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"\\nüìä LINEAR REGRESSION PERFORMANCE (Test R¬≤):\")\n",
    "        for target in self.target_names:\n",
    "            r2 = self.results['stage2'][target]['test_r2']\n",
    "            print(f\"  ‚Ä¢ {target.replace('_', ' '):<25}: R¬≤ = {r2:.4f}\")\n",
    "        \n",
    "        print(\"\\nüîç KEY FEATURE INSIGHTS (Normalized Importance):\")\n",
    "        for target in self.target_names:\n",
    "            print(f\"\\n  {target.replace('_', ' ').upper()}:\")\n",
    "            results = self.results['stage2'][target]\n",
    "            importance_df = pd.DataFrame({\n",
    "                'Feature': self.feature_names,\n",
    "                'Importance': results['feature_importance']\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            for _, row in importance_df.iterrows():\n",
    "                print(f\"    - {row['Feature']:<30}: {row['Importance']:.3f}\")\n",
    "        \n",
    "        print(\"\\nüìà ADVANCED CORRELATION INSIGHTS:\")\n",
    "        print(\"  Sliding window analysis reveals how the correlation between disaster\")\n",
    "        print(\"  indicators and system costs changes across different levels of\")\n",
    "        print(\"  renewable energy penetration, highlighting complex interactions.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ COMPREHENSIVE ANALYSIS COMPLETED!\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    def plot_multi_target_correlation_trends(self):\n",
    "        \"\"\"\n",
    "        Plot correlation trends for all target variables in a single plot,\n",
    "        with specified colors for different cost types.\n",
    "        \"\"\"\n",
    "        # Save original font and set to Arial for this plot only\n",
    "        original_font = plt.rcParams['font.family']\n",
    "        plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "        try:\n",
    "            renewable_col = 'Renewable_Penetration'\n",
    "            # Only use PDI for the correlation analysis\n",
    "            disaster_features = ['PDI']\n",
    "            data = self.data\n",
    "            \n",
    "            window_size = 0.2  # Á™óÂè£Â§ßÂ∞èÂèÇÊï∞ÔºåÊéßÂà∂ÊªëÂä®Á™óÂè£ÁöÑÂÆΩÂ∫¶\n",
    "            step_size = 0.05   # Ê≠•ÈïøÂèÇÊï∞ÔºåÊéßÂà∂Á™óÂè£ÁßªÂä®ÁöÑÈó¥Èöî\n",
    "            renewable_min, renewable_max = data[renewable_col].min(), 1\n",
    "            print(f'renewable_min:{renewable_min}, renewable_max:{renewable_max}')\n",
    "            window_centers = np.arange(renewable_min + window_size / 2, renewable_max - window_size / 2, step_size)\n",
    "            \n",
    "            # Create a single plot for all cost types\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(8, 3),dpi=300)\n",
    "            \n",
    "            # Specified colors for different cost types\n",
    "            cost_colors = ['#1f77b4', '#2ca02c', '#ff7f0e']  # ‰∏âÁßçÊàêÊú¨Á±ªÂûãÁöÑÊåáÂÆöÈ¢úËâ≤\n",
    "            \n",
    "            # Cost type labels mapping\n",
    "            cost_labels = {\n",
    "                'Renewable_Cost': 'Renewable Generation Cost',\n",
    "                'Total_Storage_Investment': 'Energy Storage System Cost', \n",
    "                'LNG_Cost': 'LNG Cost'\n",
    "            }\n",
    "            \n",
    "            # Plot correlation trends for each cost type\n",
    "            for target_idx, target in enumerate(self.target_names):\n",
    "                for feature_idx, feature in enumerate(disaster_features):\n",
    "                    correlations, p_values, valid_centers = [], [], []\n",
    "                    for center in window_centers:\n",
    "                        window_mask = (data[renewable_col] >= center - window_size / 2) & (data[renewable_col] <= center + window_size / 2)\n",
    "                        window_data = data[window_mask]\n",
    "                        if len(window_data) > 15:  # ÊúÄÂ∞èÊ†∑Êú¨ÈáèÂèÇÊï∞ÔºåÁ°Æ‰øùÁªüËÆ°ÁªìÊûúÁöÑÂèØÈù†ÊÄß\n",
    "                            corr, p_value = pearsonr(window_data[feature], window_data[target])\n",
    "                            correlations.append(corr)\n",
    "                            p_values.append(p_value)\n",
    "                            valid_centers.append(center)\n",
    "                    \n",
    "                    if len(correlations) > 2:\n",
    "                        # Use specified colors for each cost type\n",
    "                        color = cost_colors[target_idx]\n",
    "                        cost_label = cost_labels[target]\n",
    "                        \n",
    "                        # Plot correlation trend line\n",
    "                        ax.plot(valid_centers, correlations, '-', color=color, lw=2, alpha=0.9, label=cost_label)\n",
    "                        ax.scatter(valid_centers, correlations, color=color, s=25, alpha=0.7, edgecolors='white', lw=0.5, zorder=3)\n",
    "                        \n",
    "                        # Add squares for significant points\n",
    "                        sig_centers = [c for c, p in zip(valid_centers, p_values) if p < 0.05]\n",
    "                        sig_corrs = [corr for corr, p in zip(correlations, p_values) if p < 0.05]\n",
    "                        if sig_centers:\n",
    "                            ax.scatter(sig_centers, sig_corrs, s=35, color=color, marker='s', edgecolors='black', lw=0.8, zorder=4)\n",
    "\n",
    "            # Set plot properties\n",
    "            ax.axhline(y=0, color='#666666', ls='-', alpha=0.4, lw=0.8)  # Èõ∂Á∫øÂèÇËÄÉ\n",
    "            ax.set_ylabel('Correlation coefficient', fontsize=16)  # Áõ∏ÂÖ≥Á≥ªÊï∞Ê†áÁ≠æ\n",
    "            ax.set_xlabel('Renewable energy penetration', fontsize=16)  # ÂèØÂÜçÁîüËÉΩÊ∫êÊ∏óÈÄèÁéáÊ†áÁ≠æ\n",
    "            ax.set_ylim(-1, 1)  # YËΩ¥ËåÉÂõ¥ÂèÇÊï∞\n",
    "            ax.set_yticks(np.arange(-1.0, 1.1, 0.2))  # YËΩ¥ÂàªÂ∫¶ÂèÇÊï∞\n",
    "            ax.grid(True, alpha=0.2, lw=0.5)  # ÁΩëÊ†ºÁ∫øÂèÇÊï∞\n",
    "            \n",
    "            # Set title\n",
    "            ax.set_title('Disaster impacts on energy system costs', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Add legend for cost types\n",
    "            ax.legend(loc='upper right', frameon=False, fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        finally:\n",
    "            # Restore the original font settings\n",
    "            plt.rcParams['font.family'] = original_font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    \n",
    "    analyzer = AdvancedEnergyAnalysis(random_state=42)\n",
    "    \n",
    "    print(\"Advanced Energy System Investment Analysis\")\n",
    "    print(\"Using streamlined progressive modeling approach:\")\n",
    "    print(\"  1. Correlation Analysis (Global View)\")\n",
    "    print(\"  2. Linear Modeling (Performance Evaluation)\")\n",
    "    print(\"  3. Deep Interpretation (Coefficient Analysis)\")\n",
    "    print(\"  4. Advanced Correlation (Sliding Window Analysis)\\n\")\n",
    "    \n",
    "    df = analyzer.calculate_real_data()\n",
    "    if df is None:\n",
    "        exit(1)\n",
    "    \n",
    "    df_cleaned = analyzer.apply_data_cleaning(strategy='moderate')\n",
    "    if len(df_cleaned) < 30:\n",
    "        print(\"‚ùå Insufficient data after cleaning. Halting analysis.\")\n",
    "        exit(1)\n",
    "    \n",
    "    try:\n",
    "        # Execute streamlined analysis stages\n",
    "        analyzer.stage1_correlation_analysis()\n",
    "        analyzer.stage2_linear_modeling()\n",
    "        analyzer.stage3_deep_interpretation()\n",
    "        with open('analysis_cache.pkl', 'wb') as f:\n",
    "            pickle.dump(analyzer, f)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Analysis failed with error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5188657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Analysis object loaded from cache.\n",
      "\n",
      "================================================================================\n",
      "üß™ STAGE 4: ADVANCED CORRELATION ANALYSIS (SLIDING WINDOW)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     loaded_analysis = pickle.load(f)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Analysis object loaded from cache.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstage4_advanced_correlation_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m analyzer.generate_comprehensive_report()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 448\u001b[39m, in \u001b[36mAdvancedEnergyAnalysis.stage4_advanced_correlation_analysis\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müß™ STAGE 4: ADVANCED CORRELATION ANALYSIS (SLIDING WINDOW)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    446\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mplot_multi_target_correlation_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 504\u001b[39m, in \u001b[36mAdvancedEnergyAnalysis.plot_multi_target_correlation_trends\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    502\u001b[39m window_size = \u001b[32m0.25\u001b[39m  \u001b[38;5;66;03m# Á™óÂè£Â§ßÂ∞èÂèÇÊï∞ÔºåÊéßÂà∂ÊªëÂä®Á™óÂè£ÁöÑÂÆΩÂ∫¶\u001b[39;00m\n\u001b[32m    503\u001b[39m step_size = \u001b[32m0.05\u001b[39m   \u001b[38;5;66;03m# Ê≠•ÈïøÂèÇÊï∞ÔºåÊéßÂà∂Á™óÂè£ÁßªÂä®ÁöÑÈó¥Èöî\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m renewable_min, renewable_max = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrenewable_col\u001b[49m\u001b[43m]\u001b[49m.min(), \u001b[32m0.8\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrenewable_min:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrenewable_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, renewable_max:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrenewable_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    506\u001b[39m window_centers = np.arange(renewable_min + window_size / \u001b[32m2\u001b[39m, renewable_max - window_size / \u001b[32m2\u001b[39m, step_size)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "with open('analysis_cache.pkl', 'rb') as f:\n",
    "    loaded_analysis = pickle.load(f)\n",
    "print(\"‚úÖ Analysis object loaded from cache.\")\n",
    "analyzer.stage4_advanced_correlation_analysis()\n",
    "analyzer.generate_comprehensive_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "island",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
